{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3FTJpZ6aZmQK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/sign_mnist_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/sign_mnist_test.csv\")"
      ],
      "metadata": {
        "id": "oPXtF8zbZrdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate labels and pixel values\n",
        "labels_train = df_train.iloc[:, 0].values\n",
        "pixels_train = df_train.iloc[:, 1:].values\n",
        "print(f\"labels = {labels_train}\\npixels = {pixels_train}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIm6W1IgaV50",
        "outputId": "4b7dd36e-540e-4af0-8aba-b99ecd62a088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels = [ 3  6  2 ... 18 17 23]\n",
            "pixels = [[107 118 127 ... 204 203 202]\n",
            " [155 157 156 ... 103 135 149]\n",
            " [187 188 188 ... 195 194 195]\n",
            " ...\n",
            " [174 174 174 ... 202 200 200]\n",
            " [177 181 184 ...  64  87  93]\n",
            " [179 180 180 ... 205 209 215]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate labels and pixel values\n",
        "labels_test = df_test.iloc[:, 0].values\n",
        "pixels_test = df_test.iloc[:, 1:].values\n",
        "print(f\"labels = {labels_test}\\npixels = {pixels_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaYXF159aWLf",
        "outputId": "9c6db9d0-bdaa-4ed0-9bee-af64f132768b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels = [ 6  5 10 ...  2  4  2]\n",
            "pixels = [[149 149 150 ... 112 120 107]\n",
            " [126 128 131 ... 184 182 180]\n",
            " [ 85  88  92 ... 225 224 222]\n",
            " ...\n",
            " [190 191 190 ... 211 209 208]\n",
            " [201 205 208 ...  67  70  63]\n",
            " [173 174 173 ... 195 193 192]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes, dropout=0.5):\n",
        "      super(AlexNet, self).__init__()\n",
        "      self.features = nn.Sequential(\n",
        "          nn.Conv2d(1, 64, 5, stride=1, padding=2),  # Adjusted kernel size, stride, and padding\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),  # Adjusted kernel size and stride\n",
        "          nn.Conv2d(64, 192, 5, stride=1, padding=2),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2)  # Adjusted kernel size and stride\n",
        "      )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Dropout(p=dropout),\n",
        "          nn.Linear(256 * 3 * 3, 4096),  # Adjusted dimensions based on feature map size\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(p=dropout),\n",
        "          nn.Linear(4096, 4096),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(4096, num_classes),  # Adjusted to match the number of classes\n",
        "          nn.Softmax(dim=1)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.features(x)\n",
        "      x = torch.flatten(x, start_dim=1)  # Flatten the tensor\n",
        "      x = self.classifier(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "kYblqCmtaWNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = df_train.iloc[:, 0].nunique()\n",
        "print(f'Number of unique labels: {NUM_CLASSES}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMjeAy4MaWQA",
        "outputId": "717eebe0-b1be-4f44-923f-77552c0522ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AlexNet(num_classes=NUM_CLASSES).to(device)\n",
        "epochs = 500 # number of single passes on the network\n",
        "loss_fnPrecents = nn.CrossEntropyLoss(ignore_index=24)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "K75HBJlEaWSw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, pixels, labels, transform=None):\n",
        "        self.pixels = pixels\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.pixels[idx].reshape(28, 28).astype('float32')\n",
        "        label = self.labels[idx].astype('int64')  # Ensure labels are of type int64\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "yIY4w96gaWVN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_dataset = CustomDataset(pixels_train, labels_train, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=100)"
      ],
      "metadata": {
        "id": "OZw9JRNRaWXl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, dataloader, epochs, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data, targets = data.to(device), targets.to(device)  # Ensure data and targets are on the correct device\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n",
        "    print(f\"Total Correct: {correct}\")\n",
        "    print(f\"Total Samples: {total}\")\n",
        "    print(f\"Accuracy: {accuracy}%\")"
      ],
      "metadata": {
        "id": "p9WycVQfaWaO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            epochs=epochs,\n",
        "            optimizer=optimizer,\n",
        "            loss_fn=loss_fnPrecents,\n",
        "            device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VgzfwNhaWcw",
        "outputId": "24aab84c-ec19-4281-ebf0-2563ab044a96"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Loss: 3.1747\n",
            "Epoch [2/500], Loss: 3.1620\n",
            "Epoch [3/500], Loss: 3.1155\n",
            "Epoch [4/500], Loss: 3.0590\n",
            "Epoch [5/500], Loss: 2.9915\n",
            "Epoch [6/500], Loss: 2.9474\n",
            "Epoch [7/500], Loss: 2.9249\n",
            "Epoch [8/500], Loss: 2.9097\n",
            "Epoch [9/500], Loss: 2.8998\n",
            "Epoch [10/500], Loss: 2.8696\n",
            "Epoch [11/500], Loss: 2.8544\n",
            "Epoch [12/500], Loss: 2.8480\n",
            "Epoch [13/500], Loss: 2.8438\n",
            "Epoch [14/500], Loss: 2.8419\n",
            "Epoch [15/500], Loss: 2.8187\n",
            "Epoch [16/500], Loss: 2.7982\n",
            "Epoch [17/500], Loss: 2.7715\n",
            "Epoch [18/500], Loss: 2.7628\n",
            "Epoch [19/500], Loss: 2.7560\n",
            "Epoch [20/500], Loss: 2.7540\n",
            "Epoch [21/500], Loss: 2.7519\n",
            "Epoch [22/500], Loss: 2.7507\n",
            "Epoch [23/500], Loss: 2.7497\n",
            "Epoch [24/500], Loss: 2.7488\n",
            "Epoch [25/500], Loss: 2.7479\n",
            "Epoch [26/500], Loss: 2.7475\n",
            "Epoch [27/500], Loss: 2.7466\n",
            "Epoch [28/500], Loss: 2.7213\n",
            "Epoch [29/500], Loss: 2.7061\n",
            "Epoch [30/500], Loss: 2.7031\n",
            "Epoch [31/500], Loss: 2.7018\n",
            "Epoch [32/500], Loss: 2.7012\n",
            "Epoch [33/500], Loss: 2.7006\n",
            "Epoch [34/500], Loss: 2.7005\n",
            "Epoch [35/500], Loss: 2.7003\n",
            "Epoch [36/500], Loss: 2.6997\n",
            "Epoch [37/500], Loss: 2.6998\n",
            "Epoch [38/500], Loss: 2.6993\n",
            "Epoch [39/500], Loss: 2.6990\n",
            "Epoch [40/500], Loss: 2.6988\n",
            "Epoch [41/500], Loss: 2.6930\n",
            "Epoch [42/500], Loss: 2.6704\n",
            "Epoch [43/500], Loss: 2.6434\n",
            "Epoch [44/500], Loss: 2.6295\n",
            "Epoch [45/500], Loss: 2.6271\n",
            "Epoch [46/500], Loss: 2.6256\n",
            "Epoch [47/500], Loss: 2.6250\n",
            "Epoch [48/500], Loss: 2.6253\n",
            "Epoch [49/500], Loss: 2.6240\n",
            "Epoch [50/500], Loss: 2.6237\n",
            "Epoch [51/500], Loss: 2.6237\n",
            "Epoch [52/500], Loss: 2.6236\n",
            "Epoch [53/500], Loss: 2.6233\n",
            "Epoch [54/500], Loss: 2.6229\n",
            "Epoch [55/500], Loss: 2.6229\n",
            "Epoch [56/500], Loss: 2.6229\n",
            "Epoch [57/500], Loss: 2.6227\n",
            "Epoch [58/500], Loss: 2.6224\n",
            "Epoch [59/500], Loss: 2.5879\n",
            "Epoch [60/500], Loss: 2.5806\n",
            "Epoch [61/500], Loss: 2.5793\n",
            "Epoch [62/500], Loss: 2.5789\n",
            "Epoch [63/500], Loss: 2.5785\n",
            "Epoch [64/500], Loss: 2.5783\n",
            "Epoch [65/500], Loss: 2.5777\n",
            "Epoch [66/500], Loss: 2.5775\n",
            "Epoch [67/500], Loss: 2.5772\n",
            "Epoch [68/500], Loss: 2.5774\n",
            "Epoch [69/500], Loss: 2.5773\n",
            "Epoch [70/500], Loss: 2.5771\n",
            "Epoch [71/500], Loss: 2.5769\n",
            "Epoch [72/500], Loss: 2.5770\n",
            "Epoch [73/500], Loss: 2.5770\n",
            "Epoch [74/500], Loss: 2.5767\n",
            "Epoch [75/500], Loss: 2.5656\n",
            "Epoch [76/500], Loss: 2.5410\n",
            "Epoch [77/500], Loss: 2.5249\n",
            "Epoch [78/500], Loss: 2.5060\n",
            "Epoch [79/500], Loss: 2.5007\n",
            "Epoch [80/500], Loss: 2.4973\n",
            "Epoch [81/500], Loss: 2.4965\n",
            "Epoch [82/500], Loss: 2.4955\n",
            "Epoch [83/500], Loss: 2.4956\n",
            "Epoch [84/500], Loss: 2.4944\n",
            "Epoch [85/500], Loss: 2.4943\n",
            "Epoch [86/500], Loss: 2.4938\n",
            "Epoch [87/500], Loss: 2.4938\n",
            "Epoch [88/500], Loss: 2.4937\n",
            "Epoch [89/500], Loss: 2.4933\n",
            "Epoch [90/500], Loss: 2.4934\n",
            "Epoch [91/500], Loss: 2.4932\n",
            "Epoch [92/500], Loss: 2.4933\n",
            "Epoch [93/500], Loss: 2.4931\n",
            "Epoch [94/500], Loss: 2.4927\n",
            "Epoch [95/500], Loss: 2.4913\n",
            "Epoch [96/500], Loss: 2.4626\n",
            "Epoch [97/500], Loss: 2.4568\n",
            "Epoch [98/500], Loss: 2.4549\n",
            "Epoch [99/500], Loss: 2.4540\n",
            "Epoch [100/500], Loss: 2.4541\n",
            "Epoch [101/500], Loss: 2.4536\n",
            "Epoch [102/500], Loss: 2.4535\n",
            "Epoch [103/500], Loss: 2.4530\n",
            "Epoch [104/500], Loss: 2.4527\n",
            "Epoch [105/500], Loss: 2.4526\n",
            "Epoch [106/500], Loss: 2.4527\n",
            "Epoch [107/500], Loss: 2.4527\n",
            "Epoch [108/500], Loss: 2.4525\n",
            "Epoch [109/500], Loss: 2.4528\n",
            "Epoch [110/500], Loss: 2.4522\n",
            "Epoch [111/500], Loss: 2.4522\n",
            "Epoch [112/500], Loss: 2.4522\n",
            "Epoch [113/500], Loss: 2.4520\n",
            "Epoch [114/500], Loss: 2.4520\n",
            "Epoch [115/500], Loss: 2.4520\n",
            "Epoch [116/500], Loss: 2.4518\n",
            "Epoch [117/500], Loss: 2.4519\n",
            "Epoch [118/500], Loss: 2.4517\n",
            "Epoch [119/500], Loss: 2.4517\n",
            "Epoch [120/500], Loss: 2.4516\n",
            "Epoch [121/500], Loss: 2.4516\n",
            "Epoch [122/500], Loss: 2.4516\n",
            "Epoch [123/500], Loss: 2.4514\n",
            "Epoch [124/500], Loss: 2.4515\n",
            "Epoch [125/500], Loss: 2.4514\n",
            "Epoch [126/500], Loss: 2.4514\n",
            "Epoch [127/500], Loss: 2.4513\n",
            "Epoch [128/500], Loss: 2.4512\n",
            "Epoch [129/500], Loss: 2.4513\n",
            "Epoch [130/500], Loss: 2.4512\n",
            "Epoch [131/500], Loss: 2.4513\n",
            "Epoch [132/500], Loss: 2.4513\n",
            "Epoch [133/500], Loss: 2.4510\n",
            "Epoch [134/500], Loss: 2.4512\n",
            "Epoch [135/500], Loss: 2.4510\n",
            "Epoch [136/500], Loss: 2.4512\n",
            "Epoch [137/500], Loss: 2.4509\n",
            "Epoch [138/500], Loss: 2.4509\n",
            "Epoch [139/500], Loss: 2.4509\n",
            "Epoch [140/500], Loss: 2.4509\n",
            "Epoch [141/500], Loss: 2.4510\n",
            "Epoch [142/500], Loss: 2.4507\n",
            "Epoch [143/500], Loss: 2.4507\n",
            "Epoch [144/500], Loss: 2.4507\n",
            "Epoch [145/500], Loss: 2.4509\n",
            "Epoch [146/500], Loss: 2.4506\n",
            "Epoch [147/500], Loss: 2.4506\n",
            "Epoch [148/500], Loss: 2.4417\n",
            "Epoch [149/500], Loss: 2.4135\n",
            "Epoch [150/500], Loss: 2.4110\n",
            "Epoch [151/500], Loss: 2.4108\n",
            "Epoch [152/500], Loss: 2.4105\n",
            "Epoch [153/500], Loss: 2.4099\n",
            "Epoch [154/500], Loss: 2.4101\n",
            "Epoch [155/500], Loss: 2.4099\n",
            "Epoch [156/500], Loss: 2.4098\n",
            "Epoch [157/500], Loss: 2.4096\n",
            "Epoch [158/500], Loss: 2.4097\n",
            "Epoch [159/500], Loss: 2.4094\n",
            "Epoch [160/500], Loss: 2.4094\n",
            "Epoch [161/500], Loss: 2.4093\n",
            "Epoch [162/500], Loss: 2.4094\n",
            "Epoch [163/500], Loss: 2.4094\n",
            "Epoch [164/500], Loss: 2.4091\n",
            "Epoch [165/500], Loss: 2.4091\n",
            "Epoch [166/500], Loss: 2.4091\n",
            "Epoch [167/500], Loss: 2.4090\n",
            "Epoch [168/500], Loss: 2.3965\n",
            "Epoch [169/500], Loss: 2.3731\n",
            "Epoch [170/500], Loss: 2.3693\n",
            "Epoch [171/500], Loss: 2.3682\n",
            "Epoch [172/500], Loss: 2.3674\n",
            "Epoch [173/500], Loss: 2.3672\n",
            "Epoch [174/500], Loss: 2.3670\n",
            "Epoch [175/500], Loss: 2.3671\n",
            "Epoch [176/500], Loss: 2.3666\n",
            "Epoch [177/500], Loss: 2.3663\n",
            "Epoch [178/500], Loss: 2.3664\n",
            "Epoch [179/500], Loss: 2.3664\n",
            "Epoch [180/500], Loss: 2.3662\n",
            "Epoch [181/500], Loss: 2.3662\n",
            "Epoch [182/500], Loss: 2.3661\n",
            "Epoch [183/500], Loss: 2.3659\n",
            "Epoch [184/500], Loss: 2.3658\n",
            "Epoch [185/500], Loss: 2.3660\n",
            "Epoch [186/500], Loss: 2.3658\n",
            "Epoch [187/500], Loss: 2.3657\n",
            "Epoch [188/500], Loss: 2.3658\n",
            "Epoch [189/500], Loss: 2.3655\n",
            "Epoch [190/500], Loss: 2.3630\n",
            "Epoch [191/500], Loss: 2.3339\n",
            "Epoch [192/500], Loss: 2.3329\n",
            "Epoch [193/500], Loss: 2.3329\n",
            "Epoch [194/500], Loss: 2.3325\n",
            "Epoch [195/500], Loss: 2.3317\n",
            "Epoch [196/500], Loss: 2.3315\n",
            "Epoch [197/500], Loss: 2.3307\n",
            "Epoch [198/500], Loss: 2.3306\n",
            "Epoch [199/500], Loss: 2.3305\n",
            "Epoch [200/500], Loss: 2.3304\n",
            "Epoch [201/500], Loss: 2.3304\n",
            "Epoch [202/500], Loss: 2.3303\n",
            "Epoch [203/500], Loss: 2.3304\n",
            "Epoch [204/500], Loss: 2.3302\n",
            "Epoch [205/500], Loss: 2.3302\n",
            "Epoch [206/500], Loss: 2.3301\n",
            "Epoch [207/500], Loss: 2.3301\n",
            "Epoch [208/500], Loss: 2.3300\n",
            "Epoch [209/500], Loss: 2.3299\n",
            "Epoch [210/500], Loss: 2.3300\n",
            "Epoch [211/500], Loss: 2.3300\n",
            "Epoch [212/500], Loss: 2.3298\n",
            "Epoch [213/500], Loss: 2.3299\n",
            "Epoch [214/500], Loss: 2.3302\n",
            "Epoch [215/500], Loss: 2.3301\n",
            "Epoch [216/500], Loss: 2.3299\n",
            "Epoch [217/500], Loss: 2.3298\n",
            "Epoch [218/500], Loss: 2.3297\n",
            "Epoch [219/500], Loss: 2.3297\n",
            "Epoch [220/500], Loss: 2.3298\n",
            "Epoch [221/500], Loss: 2.3298\n",
            "Epoch [222/500], Loss: 2.3296\n",
            "Epoch [223/500], Loss: 2.3298\n",
            "Epoch [224/500], Loss: 2.3296\n",
            "Epoch [225/500], Loss: 2.3297\n",
            "Epoch [226/500], Loss: 2.3296\n",
            "Epoch [227/500], Loss: 2.3296\n",
            "Epoch [228/500], Loss: 2.3296\n",
            "Epoch [229/500], Loss: 2.3296\n",
            "Epoch [230/500], Loss: 2.3296\n",
            "Epoch [231/500], Loss: 2.3295\n",
            "Epoch [232/500], Loss: 2.3295\n",
            "Epoch [233/500], Loss: 2.3295\n",
            "Epoch [234/500], Loss: 2.3296\n",
            "Epoch [235/500], Loss: 2.3296\n",
            "Epoch [236/500], Loss: 2.3296\n",
            "Epoch [237/500], Loss: 2.3296\n",
            "Epoch [238/500], Loss: 2.3295\n",
            "Epoch [239/500], Loss: 2.3294\n",
            "Epoch [240/500], Loss: 2.3295\n",
            "Epoch [241/500], Loss: 2.3294\n",
            "Epoch [242/500], Loss: 2.3295\n",
            "Epoch [243/500], Loss: 2.3295\n",
            "Epoch [244/500], Loss: 2.3294\n",
            "Epoch [245/500], Loss: 2.3295\n",
            "Epoch [246/500], Loss: 2.3293\n",
            "Epoch [247/500], Loss: 2.3258\n",
            "Epoch [248/500], Loss: 2.2959\n",
            "Epoch [249/500], Loss: 2.2923\n",
            "Epoch [250/500], Loss: 2.2922\n",
            "Epoch [251/500], Loss: 2.2917\n",
            "Epoch [252/500], Loss: 2.2913\n",
            "Epoch [253/500], Loss: 2.2911\n",
            "Epoch [254/500], Loss: 2.2908\n",
            "Epoch [255/500], Loss: 2.2908\n",
            "Epoch [256/500], Loss: 2.2907\n",
            "Epoch [257/500], Loss: 2.2909\n",
            "Epoch [258/500], Loss: 2.2907\n",
            "Epoch [259/500], Loss: 2.2906\n",
            "Epoch [260/500], Loss: 2.2908\n",
            "Epoch [261/500], Loss: 2.2905\n",
            "Epoch [262/500], Loss: 2.2903\n",
            "Epoch [263/500], Loss: 2.2903\n",
            "Epoch [264/500], Loss: 2.2902\n",
            "Epoch [265/500], Loss: 2.2902\n",
            "Epoch [266/500], Loss: 2.2903\n",
            "Epoch [267/500], Loss: 2.2902\n",
            "Epoch [268/500], Loss: 2.2903\n",
            "Epoch [269/500], Loss: 2.2902\n",
            "Epoch [270/500], Loss: 2.2904\n",
            "Epoch [271/500], Loss: 2.2905\n",
            "Epoch [272/500], Loss: 2.2902\n",
            "Epoch [273/500], Loss: 2.2902\n",
            "Epoch [274/500], Loss: 2.2901\n",
            "Epoch [275/500], Loss: 2.2902\n",
            "Epoch [276/500], Loss: 2.2902\n",
            "Epoch [277/500], Loss: 2.2901\n",
            "Epoch [278/500], Loss: 2.2902\n",
            "Epoch [279/500], Loss: 2.2902\n",
            "Epoch [280/500], Loss: 2.2901\n",
            "Epoch [281/500], Loss: 2.2900\n",
            "Epoch [282/500], Loss: 2.2901\n",
            "Epoch [283/500], Loss: 2.2900\n",
            "Epoch [284/500], Loss: 2.2901\n",
            "Epoch [285/500], Loss: 2.2900\n",
            "Epoch [286/500], Loss: 2.2903\n",
            "Epoch [287/500], Loss: 2.2901\n",
            "Epoch [288/500], Loss: 2.2902\n",
            "Epoch [289/500], Loss: 2.2901\n",
            "Epoch [290/500], Loss: 2.2900\n",
            "Epoch [291/500], Loss: 2.2901\n",
            "Epoch [292/500], Loss: 2.2900\n",
            "Epoch [293/500], Loss: 2.2900\n",
            "Epoch [294/500], Loss: 2.2899\n",
            "Epoch [295/500], Loss: 2.2899\n",
            "Epoch [296/500], Loss: 2.2900\n",
            "Epoch [297/500], Loss: 2.2899\n",
            "Epoch [298/500], Loss: 2.2899\n",
            "Epoch [299/500], Loss: 2.2901\n",
            "Epoch [300/500], Loss: 2.2900\n",
            "Epoch [301/500], Loss: 2.2900\n",
            "Epoch [302/500], Loss: 2.2899\n",
            "Epoch [303/500], Loss: 2.2900\n",
            "Epoch [304/500], Loss: 2.2900\n",
            "Epoch [305/500], Loss: 2.2899\n",
            "Epoch [306/500], Loss: 2.2899\n",
            "Epoch [307/500], Loss: 2.2899\n",
            "Epoch [308/500], Loss: 2.2899\n",
            "Epoch [309/500], Loss: 2.2899\n",
            "Epoch [310/500], Loss: 2.2898\n",
            "Epoch [311/500], Loss: 2.2899\n",
            "Epoch [312/500], Loss: 2.2900\n",
            "Epoch [313/500], Loss: 2.2898\n",
            "Epoch [314/500], Loss: 2.2898\n",
            "Epoch [315/500], Loss: 2.2899\n",
            "Epoch [316/500], Loss: 2.2899\n",
            "Epoch [317/500], Loss: 2.2898\n",
            "Epoch [318/500], Loss: 2.2898\n",
            "Epoch [319/500], Loss: 2.2788\n",
            "Epoch [320/500], Loss: 2.2482\n",
            "Epoch [321/500], Loss: 2.2478\n",
            "Epoch [322/500], Loss: 2.2479\n",
            "Epoch [323/500], Loss: 2.2477\n",
            "Epoch [324/500], Loss: 2.2480\n",
            "Epoch [325/500], Loss: 2.2476\n",
            "Epoch [326/500], Loss: 2.2476\n",
            "Epoch [327/500], Loss: 2.2474\n",
            "Epoch [328/500], Loss: 2.2478\n",
            "Epoch [329/500], Loss: 2.2477\n",
            "Epoch [330/500], Loss: 2.2479\n",
            "Epoch [331/500], Loss: 2.2477\n",
            "Epoch [332/500], Loss: 2.2474\n",
            "Epoch [333/500], Loss: 2.2474\n",
            "Epoch [334/500], Loss: 2.2476\n",
            "Epoch [335/500], Loss: 2.2474\n",
            "Epoch [336/500], Loss: 2.2474\n",
            "Epoch [337/500], Loss: 2.2474\n",
            "Epoch [338/500], Loss: 2.2474\n",
            "Epoch [339/500], Loss: 2.2475\n",
            "Epoch [340/500], Loss: 2.2473\n",
            "Epoch [341/500], Loss: 2.2475\n",
            "Epoch [342/500], Loss: 2.2474\n",
            "Epoch [343/500], Loss: 2.2473\n",
            "Epoch [344/500], Loss: 2.2474\n",
            "Epoch [345/500], Loss: 2.2474\n",
            "Epoch [346/500], Loss: 2.2474\n",
            "Epoch [347/500], Loss: 2.2474\n",
            "Epoch [348/500], Loss: 2.2475\n",
            "Epoch [349/500], Loss: 2.2475\n",
            "Epoch [350/500], Loss: 2.2474\n",
            "Epoch [351/500], Loss: 2.2474\n",
            "Epoch [352/500], Loss: 2.2475\n",
            "Epoch [353/500], Loss: 2.2475\n",
            "Epoch [354/500], Loss: 2.2475\n",
            "Epoch [355/500], Loss: 2.2474\n",
            "Epoch [356/500], Loss: 2.2473\n",
            "Epoch [357/500], Loss: 2.2474\n",
            "Epoch [358/500], Loss: 2.2474\n",
            "Epoch [359/500], Loss: 2.2473\n",
            "Epoch [360/500], Loss: 2.2475\n",
            "Epoch [361/500], Loss: 2.2474\n",
            "Epoch [362/500], Loss: 2.2473\n",
            "Epoch [363/500], Loss: 2.2473\n",
            "Epoch [364/500], Loss: 2.2473\n",
            "Epoch [365/500], Loss: 2.2474\n",
            "Epoch [366/500], Loss: 2.2473\n",
            "Epoch [367/500], Loss: 2.2474\n",
            "Epoch [368/500], Loss: 2.2473\n",
            "Epoch [369/500], Loss: 2.2474\n",
            "Epoch [370/500], Loss: 2.2473\n",
            "Epoch [371/500], Loss: 2.2474\n",
            "Epoch [372/500], Loss: 2.2475\n",
            "Epoch [373/500], Loss: 2.2474\n",
            "Epoch [374/500], Loss: 2.2474\n",
            "Epoch [375/500], Loss: 2.2474\n",
            "Epoch [376/500], Loss: 2.2475\n",
            "Epoch [377/500], Loss: 2.2474\n",
            "Epoch [378/500], Loss: 2.2473\n",
            "Epoch [379/500], Loss: 2.2474\n",
            "Epoch [380/500], Loss: 2.2475\n",
            "Epoch [381/500], Loss: 2.2473\n",
            "Epoch [382/500], Loss: 2.2474\n",
            "Epoch [383/500], Loss: 2.2473\n",
            "Epoch [384/500], Loss: 2.2474\n",
            "Epoch [385/500], Loss: 2.2473\n",
            "Epoch [386/500], Loss: 2.2473\n",
            "Epoch [387/500], Loss: 2.2473\n",
            "Epoch [388/500], Loss: 2.2475\n",
            "Epoch [389/500], Loss: 2.2473\n",
            "Epoch [390/500], Loss: 2.2473\n",
            "Epoch [391/500], Loss: 2.2474\n",
            "Epoch [392/500], Loss: 2.2472\n",
            "Epoch [393/500], Loss: 2.2475\n",
            "Epoch [394/500], Loss: 2.2473\n",
            "Epoch [395/500], Loss: 2.2473\n",
            "Epoch [396/500], Loss: 2.2473\n",
            "Epoch [397/500], Loss: 2.2474\n",
            "Epoch [398/500], Loss: 2.2472\n",
            "Epoch [399/500], Loss: 2.2473\n",
            "Epoch [400/500], Loss: 2.2474\n",
            "Epoch [401/500], Loss: 2.2474\n",
            "Epoch [402/500], Loss: 2.2475\n",
            "Epoch [403/500], Loss: 2.2475\n",
            "Epoch [404/500], Loss: 2.2473\n",
            "Epoch [405/500], Loss: 2.2473\n",
            "Epoch [406/500], Loss: 2.2473\n",
            "Epoch [407/500], Loss: 2.2473\n",
            "Epoch [408/500], Loss: 2.2473\n",
            "Epoch [409/500], Loss: 2.2473\n",
            "Epoch [410/500], Loss: 2.2473\n",
            "Epoch [411/500], Loss: 2.2473\n",
            "Epoch [412/500], Loss: 2.2474\n",
            "Epoch [413/500], Loss: 2.2474\n",
            "Epoch [414/500], Loss: 2.2473\n",
            "Epoch [415/500], Loss: 2.2473\n",
            "Epoch [416/500], Loss: 2.2473\n",
            "Epoch [417/500], Loss: 2.2472\n",
            "Epoch [418/500], Loss: 2.2473\n",
            "Epoch [419/500], Loss: 2.2473\n",
            "Epoch [420/500], Loss: 2.2473\n",
            "Epoch [421/500], Loss: 2.2473\n",
            "Epoch [422/500], Loss: 2.2472\n",
            "Epoch [423/500], Loss: 2.2473\n",
            "Epoch [424/500], Loss: 2.2473\n",
            "Epoch [425/500], Loss: 2.2473\n",
            "Epoch [426/500], Loss: 2.2472\n",
            "Epoch [427/500], Loss: 2.2474\n",
            "Epoch [428/500], Loss: 2.2472\n",
            "Epoch [429/500], Loss: 2.2474\n",
            "Epoch [430/500], Loss: 2.2474\n",
            "Epoch [431/500], Loss: 2.2473\n",
            "Epoch [432/500], Loss: 2.2473\n",
            "Epoch [433/500], Loss: 2.2473\n",
            "Epoch [434/500], Loss: 2.2472\n",
            "Epoch [435/500], Loss: 2.2472\n",
            "Epoch [436/500], Loss: 2.2473\n",
            "Epoch [437/500], Loss: 2.2473\n",
            "Epoch [438/500], Loss: 2.2473\n",
            "Epoch [439/500], Loss: 2.2474\n",
            "Epoch [440/500], Loss: 2.2473\n",
            "Epoch [441/500], Loss: 2.2472\n",
            "Epoch [442/500], Loss: 2.2473\n",
            "Epoch [443/500], Loss: 2.2473\n",
            "Epoch [444/500], Loss: 2.2473\n",
            "Epoch [445/500], Loss: 2.2473\n",
            "Epoch [446/500], Loss: 2.2473\n",
            "Epoch [447/500], Loss: 2.2473\n",
            "Epoch [448/500], Loss: 2.2473\n",
            "Epoch [449/500], Loss: 2.2473\n",
            "Epoch [450/500], Loss: 2.2473\n",
            "Epoch [451/500], Loss: 2.2472\n",
            "Epoch [452/500], Loss: 2.2473\n",
            "Epoch [453/500], Loss: 2.2473\n",
            "Epoch [454/500], Loss: 2.2472\n",
            "Epoch [455/500], Loss: 2.2473\n",
            "Epoch [456/500], Loss: 2.2473\n",
            "Epoch [457/500], Loss: 2.2473\n",
            "Epoch [458/500], Loss: 2.2473\n",
            "Epoch [459/500], Loss: 2.2473\n",
            "Epoch [460/500], Loss: 2.2473\n",
            "Epoch [461/500], Loss: 2.2472\n",
            "Epoch [462/500], Loss: 2.2472\n",
            "Epoch [463/500], Loss: 2.2473\n",
            "Epoch [464/500], Loss: 2.2472\n",
            "Epoch [465/500], Loss: 2.2473\n",
            "Epoch [466/500], Loss: 2.2472\n",
            "Epoch [467/500], Loss: 2.2472\n",
            "Epoch [468/500], Loss: 2.2473\n",
            "Epoch [469/500], Loss: 2.2473\n",
            "Epoch [470/500], Loss: 2.2474\n",
            "Epoch [471/500], Loss: 2.2473\n",
            "Epoch [472/500], Loss: 2.2473\n",
            "Epoch [473/500], Loss: 2.2472\n",
            "Epoch [474/500], Loss: 2.2473\n",
            "Epoch [475/500], Loss: 2.2473\n",
            "Epoch [476/500], Loss: 2.2472\n",
            "Epoch [477/500], Loss: 2.2472\n",
            "Epoch [478/500], Loss: 2.2473\n",
            "Epoch [479/500], Loss: 2.2473\n",
            "Epoch [480/500], Loss: 2.2472\n",
            "Epoch [481/500], Loss: 2.2473\n",
            "Epoch [482/500], Loss: 2.2472\n",
            "Epoch [483/500], Loss: 2.2473\n",
            "Epoch [484/500], Loss: 2.2473\n",
            "Epoch [485/500], Loss: 2.2473\n",
            "Epoch [486/500], Loss: 2.2473\n",
            "Epoch [487/500], Loss: 2.2472\n",
            "Epoch [488/500], Loss: 2.2473\n",
            "Epoch [489/500], Loss: 2.2472\n",
            "Epoch [490/500], Loss: 2.2473\n",
            "Epoch [491/500], Loss: 2.2474\n",
            "Epoch [492/500], Loss: 2.2473\n",
            "Epoch [493/500], Loss: 2.2473\n",
            "Epoch [494/500], Loss: 2.2473\n",
            "Epoch [495/500], Loss: 2.2472\n",
            "Epoch [496/500], Loss: 2.2473\n",
            "Epoch [497/500], Loss: 2.2472\n",
            "Epoch [498/500], Loss: 2.2473\n",
            "Epoch [499/500], Loss: 2.2473\n",
            "Epoch [500/500], Loss: 2.2474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = CustomDataset(pixels_test, labels_test, transform=transform)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=100)"
      ],
      "metadata": {
        "id": "Yvoun5hadqh6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(\n",
        "    model=model,\n",
        "    dataloader=train_dataloader,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "9mh2S4m7dfqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3b6fb3-ec50-44e5-e73d-1c36e2af021a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Correct: 26337\n",
            "Total Samples: 27455\n",
            "Accuracy: 95.92788198870879%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(\n",
        "    model=model,\n",
        "    dataloader=val_dataloader,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "7nd9yABVdeEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6815fc5f-b1fc-4eb9-c74d-242f44e19f6f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Correct: 6655\n",
            "Total Samples: 7172\n",
            "Accuracy: 92.79141104294479%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name} - parameter:\\n\", param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK1w98fsuYq5",
        "outputId": "058f312c-c1c5-4d0f-d6d5-d3b7de5b0b3b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight - parameter:\n",
            " tensor([[[[ 3.3887e-02,  1.0412e-01, -2.0227e-01,  6.6796e-02,  1.8589e-01],\n",
            "          [-1.9303e-02,  1.3635e-01,  1.7168e-01,  1.5087e-01, -1.1247e-01],\n",
            "          [-1.0118e-01, -1.4005e-01, -1.1336e-01, -1.6930e-01,  1.7974e-01],\n",
            "          [-1.7295e-01,  1.4025e-01,  9.6501e-02, -3.4034e-02,  8.5212e-02],\n",
            "          [ 1.3568e-01,  1.0634e-01,  1.0532e-01, -4.2140e-02,  1.8517e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.6751e-01,  1.3910e-01, -1.0123e-01,  7.2488e-03, -1.3555e-01],\n",
            "          [ 8.9740e-02,  7.0290e-02, -1.0404e-01,  1.0112e-01, -1.6532e-01],\n",
            "          [ 4.5242e-02,  1.2659e-01, -1.0964e-01, -3.3610e-02,  2.9541e-02],\n",
            "          [-1.5014e-02, -1.1339e-01,  1.2464e-01, -1.5295e-01,  1.2082e-01],\n",
            "          [ 1.0550e-01, -3.8845e-02,  1.6478e-01, -1.3668e-01, -1.2532e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.2475e-01,  1.0751e-02, -1.1704e-01,  1.3578e-01,  1.7022e-01],\n",
            "          [-7.1269e-02, -1.7054e-01,  8.3490e-02,  2.1340e-01, -1.0352e-01],\n",
            "          [ 5.8848e-02,  1.2889e-01,  5.0872e-02, -3.3005e-02,  6.4652e-02],\n",
            "          [-1.0844e-01, -1.4047e-01, -1.4370e-01, -1.9191e-01,  7.9412e-02],\n",
            "          [ 2.0362e-01,  1.0442e-01, -2.5082e-02, -8.2811e-02,  4.4314e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.0447e-02,  2.9161e-02, -1.8088e-01, -4.8270e-02,  1.1870e-01],\n",
            "          [-3.3585e-02, -1.4003e-01,  1.3434e-01, -1.9323e-01, -1.6046e-01],\n",
            "          [ 1.2972e-01, -1.3817e-01, -1.1547e-01, -1.6182e-01, -9.2645e-02],\n",
            "          [ 1.7205e-01,  1.7931e-01,  1.4021e-01, -1.5160e-01,  1.1757e-01],\n",
            "          [ 4.3540e-05, -1.4415e-01, -1.2985e-01, -1.0748e-01, -2.7273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.2712e-02, -4.6397e-02, -8.6953e-03,  3.8436e-02,  1.6041e-01],\n",
            "          [ 4.2101e-02,  9.0810e-03, -9.4844e-02,  9.5213e-04,  1.2831e-01],\n",
            "          [ 1.9528e-01,  4.8315e-02, -1.7042e-01, -7.6847e-02,  2.3944e-01],\n",
            "          [ 4.8717e-02, -8.4948e-02, -1.8073e-01, -1.8654e-01,  1.7185e-01],\n",
            "          [-1.4605e-01,  4.7138e-02, -1.4245e-01,  1.6148e-01,  1.7739e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.2620e-01, -1.9153e-01, -8.6735e-02,  6.1192e-02,  1.2596e-01],\n",
            "          [ 8.5329e-03,  7.8990e-03, -6.0781e-02,  3.3321e-03, -2.3968e-02],\n",
            "          [-6.1753e-02,  1.6723e-01,  2.0573e-01, -2.0619e-01, -8.2188e-02],\n",
            "          [ 5.3111e-02,  8.6920e-02,  1.6052e-01, -1.1627e-01, -1.4578e-01],\n",
            "          [ 1.5113e-01, -8.5483e-03, -5.3084e-02,  5.3154e-02,  1.8740e-01]]]],\n",
            "       device='cuda:0')\n",
            "features.0.bias - parameter:\n",
            " tensor([-0.0834,  0.1500,  0.1634,  0.0180, -0.1891, -0.0214,  0.0584, -0.1420,\n",
            "         0.0808,  0.1732, -0.1581,  0.0678, -0.1334, -0.0789,  0.0615, -0.1053,\n",
            "         0.0261,  0.1571, -0.1676,  0.1301,  0.1448, -0.1553,  0.1875, -0.0761,\n",
            "         0.0454, -0.1291, -0.0488,  0.1632,  0.1644, -0.1090, -0.0044,  0.1772,\n",
            "        -0.0796, -0.1752,  0.1220,  0.0660, -0.0744,  0.0604,  0.0031,  0.1695,\n",
            "         0.1167, -0.0860, -0.0969, -0.1055, -0.0065, -0.1940, -0.1173,  0.1486,\n",
            "         0.0818, -0.0052, -0.1970,  0.0772, -0.0477,  0.0002,  0.0376, -0.1194,\n",
            "        -0.1214,  0.1510, -0.1707, -0.1610, -0.1980, -0.1477,  0.0391,  0.1405],\n",
            "       device='cuda:0')\n",
            "features.3.weight - parameter:\n",
            " tensor([[[[-5.0955e-03,  1.7496e-02, -2.3857e-02, -1.2679e-02, -6.5951e-03],\n",
            "          [ 1.1740e-02,  1.6328e-02, -1.9880e-04, -5.4408e-03, -2.4641e-02],\n",
            "          [ 2.1708e-02, -9.8106e-03,  1.3156e-02,  1.9400e-02, -1.2998e-02],\n",
            "          [-6.3762e-03, -5.5655e-03, -1.5589e-03,  1.4082e-02,  1.7891e-02],\n",
            "          [ 2.9536e-03,  6.0114e-03,  1.9672e-02,  9.7540e-03, -1.7156e-02]],\n",
            "\n",
            "         [[-1.4130e-02, -1.2881e-02,  1.0681e-02, -2.1245e-02,  1.1985e-02],\n",
            "          [ 1.3656e-04,  1.0196e-02, -2.3581e-02, -1.2028e-02, -1.4455e-02],\n",
            "          [-2.6525e-03, -7.2943e-03,  1.5211e-02,  1.3706e-02, -1.7938e-02],\n",
            "          [-1.7623e-02, -1.1930e-02,  6.8419e-03, -9.9000e-03,  4.6001e-03],\n",
            "          [ 1.0702e-02, -1.9160e-02, -1.5011e-02,  2.4908e-02,  2.4192e-02]],\n",
            "\n",
            "         [[-2.8033e-03, -1.2971e-02, -1.0166e-03,  1.1677e-03, -2.1636e-02],\n",
            "          [ 2.2127e-03, -1.8174e-02, -1.4963e-02, -1.3009e-02, -1.8167e-02],\n",
            "          [ 1.5576e-02,  1.4343e-02, -1.1103e-02, -9.5025e-03,  5.5677e-03],\n",
            "          [-2.4702e-02,  5.6825e-04,  1.9386e-02, -1.5782e-02, -9.4634e-03],\n",
            "          [-2.4464e-02,  1.0445e-02,  1.3253e-02, -7.0105e-03, -2.2165e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.5399e-03,  2.2234e-02, -1.5451e-02, -2.3875e-02,  2.1889e-02],\n",
            "          [ 3.7532e-03, -1.8070e-02, -3.6192e-03, -1.1290e-03, -4.7314e-03],\n",
            "          [ 1.3770e-02, -2.1706e-03,  7.0564e-03,  1.7612e-02, -3.7623e-03],\n",
            "          [ 2.1314e-02, -1.8125e-02,  8.8362e-03, -1.6905e-02, -1.2718e-03],\n",
            "          [-1.5989e-02,  1.9067e-02,  1.9183e-02, -9.5290e-03,  4.4156e-03]],\n",
            "\n",
            "         [[-7.6362e-04, -1.0176e-02, -2.8542e-03, -3.4155e-03, -1.9946e-02],\n",
            "          [ 1.2140e-03,  9.4553e-03, -2.4602e-02,  1.6848e-02,  1.4917e-02],\n",
            "          [-2.1684e-02,  1.3763e-02, -1.7614e-02,  1.8382e-02, -1.6607e-02],\n",
            "          [-1.8512e-02, -1.9127e-02, -1.9338e-02,  2.4363e-02,  1.8243e-02],\n",
            "          [-7.9207e-03,  2.9381e-03,  5.5268e-04,  2.1244e-02, -1.6451e-02]],\n",
            "\n",
            "         [[ 1.7949e-02,  2.1776e-02, -9.2910e-03,  3.7372e-03,  2.2371e-02],\n",
            "          [ 2.4643e-02,  9.7531e-03,  2.0682e-02,  1.6232e-02,  1.4315e-02],\n",
            "          [-1.7181e-02,  1.1613e-02,  2.4637e-02,  3.6703e-03,  2.3407e-02],\n",
            "          [-2.0003e-02,  8.7431e-03,  1.4332e-02, -1.6636e-02, -8.7099e-03],\n",
            "          [ 2.3720e-02, -2.1986e-02, -1.0057e-02,  1.4184e-02,  2.4670e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0992e-02,  1.0646e-03, -6.7261e-03, -2.1047e-02,  2.2590e-03],\n",
            "          [ 2.1557e-02, -1.9775e-02, -1.0398e-02,  3.8172e-03,  2.0461e-02],\n",
            "          [-2.3664e-03, -1.1289e-02, -2.1017e-02,  8.4968e-03, -9.8996e-05],\n",
            "          [-1.8191e-02,  3.1610e-03, -4.2982e-03,  9.9069e-04, -1.2403e-03],\n",
            "          [-1.6870e-02, -5.5175e-03,  2.3793e-02,  1.3382e-02,  2.4330e-02]],\n",
            "\n",
            "         [[ 7.7185e-03,  2.4391e-02, -1.4064e-02, -1.0316e-02,  9.1904e-03],\n",
            "          [ 2.0557e-02,  9.6419e-03, -5.0142e-03,  1.4186e-02,  2.0403e-02],\n",
            "          [-1.6281e-02, -9.4813e-03, -2.4988e-03,  7.1923e-03, -1.6826e-02],\n",
            "          [-1.8437e-02,  4.5876e-03,  5.1132e-03, -1.1330e-02,  1.7275e-02],\n",
            "          [-9.0476e-03, -5.1178e-03, -4.5730e-03, -6.9576e-03,  3.5015e-03]],\n",
            "\n",
            "         [[-8.8239e-03, -2.3872e-02, -4.3800e-03,  1.8214e-02,  5.6083e-03],\n",
            "          [ 1.7825e-02,  1.0289e-02, -1.1481e-02,  1.7891e-02, -1.4222e-02],\n",
            "          [ 1.1225e-02,  2.4858e-02, -1.6779e-02, -1.5305e-02, -8.1732e-03],\n",
            "          [-3.0447e-03, -5.1941e-03, -4.6119e-03,  7.9694e-03, -2.9349e-03],\n",
            "          [-9.9923e-03,  9.9633e-03, -7.9038e-05,  7.9560e-03, -3.3884e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2218e-02,  2.1931e-02,  1.0288e-02,  3.8077e-03,  1.0521e-02],\n",
            "          [-2.3394e-02,  8.7326e-03,  6.9742e-03, -1.7599e-02, -1.9262e-02],\n",
            "          [ 1.6260e-02,  2.1927e-02, -4.4754e-03,  1.7277e-02,  1.4520e-02],\n",
            "          [-1.8794e-02,  1.5036e-02, -3.7449e-03,  1.1328e-02, -1.0263e-02],\n",
            "          [-1.2531e-02,  2.3838e-02,  1.1067e-02,  1.7843e-02, -6.8157e-03]],\n",
            "\n",
            "         [[ 2.3152e-02,  1.2857e-02,  1.9948e-03, -6.2960e-03,  1.9820e-02],\n",
            "          [ 2.7369e-02, -1.9205e-02, -1.0747e-02,  4.5989e-03, -2.3533e-02],\n",
            "          [-7.5175e-03,  1.1469e-02,  1.0998e-02,  7.3881e-03, -2.1590e-02],\n",
            "          [-2.2750e-02, -8.4298e-03, -8.7342e-03,  2.4249e-02,  7.3612e-03],\n",
            "          [-1.8596e-02, -1.2373e-02,  1.2527e-02,  7.0747e-03,  6.3973e-03]],\n",
            "\n",
            "         [[-2.5160e-02,  2.0639e-02,  1.8012e-02, -2.3379e-02,  1.2571e-02],\n",
            "          [ 1.1411e-02, -1.2550e-02,  2.9673e-03,  2.0084e-02,  2.5843e-02],\n",
            "          [-1.1770e-02, -1.8519e-02, -2.1031e-02,  1.0181e-02, -1.8776e-02],\n",
            "          [ 6.4057e-03, -8.6160e-03,  9.0721e-03, -1.6857e-02, -1.5750e-02],\n",
            "          [-1.3538e-02,  8.1594e-03, -7.2500e-03, -1.0853e-02, -1.2497e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0921e-02,  4.9568e-03, -5.7990e-03,  7.8408e-04,  3.1679e-03],\n",
            "          [-2.0648e-02,  2.5806e-02,  2.0918e-02, -6.2045e-03,  6.2510e-03],\n",
            "          [ 4.3666e-03,  9.6338e-03, -2.2998e-02,  1.1733e-02,  2.2082e-02],\n",
            "          [ 2.2783e-02, -5.9449e-03,  6.0038e-03, -1.0506e-02,  1.3541e-02],\n",
            "          [ 1.3893e-02,  8.0839e-03, -1.0913e-02,  1.9122e-02,  2.0543e-02]],\n",
            "\n",
            "         [[-1.0588e-02,  1.7942e-02, -1.2856e-02, -8.8904e-03, -4.7938e-03],\n",
            "          [ 1.2952e-02, -1.6157e-02, -1.7020e-02,  2.0403e-02,  1.9015e-02],\n",
            "          [ 2.0926e-02,  3.8362e-03, -1.3874e-02, -1.1196e-02, -1.2248e-02],\n",
            "          [ 6.0294e-03, -2.7927e-03, -1.8957e-02,  2.1093e-02, -3.0965e-03],\n",
            "          [-4.6562e-03, -1.4500e-02, -4.7241e-03, -1.8142e-02,  1.8244e-02]],\n",
            "\n",
            "         [[ 1.9839e-02,  2.2620e-02, -7.7174e-03, -1.5651e-02,  2.0522e-02],\n",
            "          [ 1.1851e-02,  1.2329e-02, -1.6216e-02,  1.7426e-02, -1.5158e-02],\n",
            "          [-2.2742e-02,  1.8639e-02, -2.8712e-03, -1.6647e-02,  7.7213e-03],\n",
            "          [ 6.9356e-04, -4.6972e-03, -6.9253e-03, -1.9520e-02,  1.9004e-02],\n",
            "          [ 6.7448e-03,  1.1623e-02, -1.2395e-02, -7.7287e-03, -1.4843e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4413e-02,  1.5250e-02, -1.5368e-02,  1.3873e-02,  4.8291e-03],\n",
            "          [ 8.7793e-03,  1.0045e-02,  2.4773e-02, -3.7392e-03, -1.0116e-02],\n",
            "          [-8.4068e-03, -1.0904e-02, -3.6428e-03,  1.8224e-02, -1.3858e-02],\n",
            "          [-2.5307e-04,  1.9870e-02, -1.5032e-02, -1.5967e-02,  2.2699e-02],\n",
            "          [ 3.0363e-03, -6.7815e-03, -1.4093e-02,  1.6992e-02, -4.9486e-03]],\n",
            "\n",
            "         [[-2.4266e-02, -1.3828e-02, -1.0957e-02, -2.0197e-02, -2.5737e-02],\n",
            "          [ 2.7541e-02, -2.7249e-02,  2.0925e-02, -1.7658e-02, -2.1257e-02],\n",
            "          [ 1.9144e-02, -4.0124e-03,  2.9774e-02,  1.3641e-03, -1.7352e-02],\n",
            "          [-1.4646e-02, -2.4420e-02,  2.6891e-02, -2.1206e-03,  2.2736e-02],\n",
            "          [ 2.2780e-02,  1.5977e-02,  3.2610e-02,  2.9682e-03,  1.7327e-02]],\n",
            "\n",
            "         [[ 2.2849e-02, -2.0126e-02, -1.9607e-02,  2.2867e-02, -1.9600e-02],\n",
            "          [-6.3847e-03, -1.8752e-02,  1.8527e-02,  5.3735e-03, -2.4390e-02],\n",
            "          [ 1.0971e-02, -5.3649e-03, -1.8947e-02,  1.7638e-02, -7.7656e-03],\n",
            "          [ 1.8577e-02,  1.9642e-02,  1.6178e-02,  1.9422e-02, -1.9907e-02],\n",
            "          [-6.2219e-03,  2.2532e-02,  2.5712e-03,  6.5174e-03,  2.3227e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.8811e-03, -8.3647e-03,  1.0223e-02,  2.4694e-02, -1.6413e-02],\n",
            "          [-2.5546e-03, -1.1265e-02, -1.3033e-02,  1.8274e-02, -1.5318e-02],\n",
            "          [-2.4594e-02,  1.9413e-02, -1.1916e-02,  1.8757e-03, -1.0907e-02],\n",
            "          [-1.2186e-02,  1.4531e-02,  1.4704e-02, -1.8769e-02, -1.5085e-02],\n",
            "          [ 2.0728e-02, -2.1042e-02, -1.9132e-02, -2.0062e-03, -1.5096e-02]],\n",
            "\n",
            "         [[ 2.4657e-02,  7.7832e-03, -3.8088e-03,  8.7131e-03, -1.9961e-02],\n",
            "          [ 1.1428e-02, -1.7637e-02, -8.7381e-03,  1.0134e-02,  1.5188e-02],\n",
            "          [ 2.3874e-02, -1.6259e-02,  1.3841e-02, -5.6387e-03,  7.4426e-03],\n",
            "          [ 5.1874e-03,  1.7345e-02, -2.0649e-02, -7.9826e-05,  9.0926e-03],\n",
            "          [-3.0701e-03, -1.5651e-03,  1.7697e-02, -2.4277e-02,  2.4272e-02]],\n",
            "\n",
            "         [[-2.2355e-02,  1.7648e-02, -1.8022e-03,  3.4673e-03, -7.4032e-03],\n",
            "          [-7.0437e-03, -1.8610e-02,  5.9409e-03,  1.0591e-02,  1.5584e-02],\n",
            "          [-1.4167e-02, -5.8264e-03,  1.1055e-04,  2.2884e-04,  6.6745e-03],\n",
            "          [-1.2686e-02,  2.3688e-02, -2.0835e-03, -3.5035e-04, -1.7749e-03],\n",
            "          [ 2.1928e-02, -9.6968e-03, -1.0695e-02, -6.3067e-03,  1.8724e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4695e-02,  2.4199e-02,  1.0991e-02,  1.2192e-04, -1.2146e-02],\n",
            "          [ 9.4609e-03,  1.4593e-02, -4.4773e-03, -1.3479e-02,  8.7010e-03],\n",
            "          [-9.3694e-03, -4.8870e-03,  1.1804e-02, -1.9000e-03, -1.7707e-03],\n",
            "          [-7.4866e-04, -2.2751e-02, -1.2054e-02,  1.5254e-02,  1.5096e-02],\n",
            "          [ 2.8208e-03,  4.8391e-03,  6.4501e-03,  2.2290e-02, -2.5794e-03]],\n",
            "\n",
            "         [[-2.2871e-02,  1.3475e-02,  1.5624e-02, -1.3236e-02, -1.8251e-02],\n",
            "          [-8.5288e-03, -9.8706e-03, -1.5813e-02,  2.1988e-02,  1.7618e-02],\n",
            "          [-9.8385e-03, -3.9535e-03, -1.0861e-02, -2.0685e-02,  9.3755e-03],\n",
            "          [-2.2777e-02, -7.6541e-03,  5.6922e-03, -1.5403e-02,  2.4218e-02],\n",
            "          [-2.9090e-03,  1.0703e-02, -2.2291e-02, -1.4035e-02, -7.2243e-03]],\n",
            "\n",
            "         [[ 1.2042e-02,  1.2799e-02, -1.5726e-02, -2.4420e-02,  5.1390e-03],\n",
            "          [-2.1217e-02, -1.1429e-03,  1.0389e-02,  6.9331e-03, -1.5993e-02],\n",
            "          [ 4.5781e-03, -9.7561e-03,  2.4458e-02, -3.4836e-03,  6.8226e-03],\n",
            "          [ 1.3001e-02,  7.1569e-03, -3.2329e-03, -7.1786e-03,  5.4636e-03],\n",
            "          [ 2.3613e-02, -7.0574e-03, -1.9615e-02, -6.6397e-03, -1.2684e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4171e-02,  1.6040e-02, -7.3156e-03, -1.4848e-02, -2.0619e-02],\n",
            "          [-2.2216e-02, -1.3900e-02,  4.0186e-03,  1.2791e-02, -1.2552e-02],\n",
            "          [ 1.2618e-02, -3.0923e-03,  1.0973e-02,  1.7839e-02,  3.6521e-03],\n",
            "          [-1.4405e-03, -1.0752e-02,  2.5677e-02,  5.5862e-03,  2.1177e-02],\n",
            "          [-1.2609e-02, -2.3268e-02, -1.4673e-02,  6.9971e-03,  1.7866e-03]],\n",
            "\n",
            "         [[ 1.6156e-02,  9.5715e-03, -1.9742e-02,  1.5038e-02,  1.7669e-02],\n",
            "          [-5.7184e-03,  1.3688e-03, -5.4402e-03,  1.3564e-02,  1.2282e-02],\n",
            "          [ 1.9330e-02,  2.4208e-02, -9.2419e-03,  7.1556e-03,  2.3339e-02],\n",
            "          [ 1.8240e-02,  1.0910e-02,  2.0878e-02, -1.7920e-02,  1.7158e-02],\n",
            "          [-1.3969e-02, -4.5173e-03,  1.6320e-02, -1.4466e-02,  2.2825e-02]],\n",
            "\n",
            "         [[ 1.8331e-02,  4.8785e-03,  2.0232e-02,  1.1917e-02, -1.0623e-02],\n",
            "          [-1.7354e-02, -6.3569e-03, -1.0830e-02, -1.1686e-02,  2.4156e-02],\n",
            "          [-1.3850e-02,  7.9610e-03, -1.4538e-02, -4.6118e-03,  4.3909e-03],\n",
            "          [-7.0814e-03, -2.1333e-02,  6.4291e-03,  2.3239e-03,  4.1968e-03],\n",
            "          [-6.3993e-03, -3.6757e-03,  2.5177e-02, -6.3831e-03,  4.9500e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3470e-03,  1.9252e-02,  1.5349e-02, -2.2608e-02, -2.4547e-02],\n",
            "          [-1.4146e-02,  2.4721e-02,  4.1581e-03,  4.1947e-03,  1.3422e-02],\n",
            "          [-5.7671e-03,  6.2259e-04, -9.6868e-03, -1.7551e-02, -4.2055e-03],\n",
            "          [-2.3112e-02, -1.9331e-02, -1.2569e-03, -1.0357e-02,  1.8150e-02],\n",
            "          [ 2.3419e-02, -1.8054e-02, -1.8773e-02,  2.8132e-03,  2.2757e-02]],\n",
            "\n",
            "         [[-1.4968e-03, -1.3364e-02,  1.3168e-02,  2.0388e-02,  1.6463e-02],\n",
            "          [-5.3417e-03, -1.2519e-02, -1.1664e-02, -1.1283e-02,  1.1443e-02],\n",
            "          [-1.7485e-02, -7.7945e-03, -1.8944e-02,  5.0983e-03,  2.1078e-02],\n",
            "          [-1.6419e-02,  5.9161e-03,  2.3123e-03,  5.8264e-03, -3.7133e-03],\n",
            "          [-2.5252e-02, -1.5428e-02,  3.1510e-03, -1.8180e-02,  6.4871e-03]],\n",
            "\n",
            "         [[ 1.8733e-02,  5.1239e-03,  5.2155e-04,  2.7940e-02, -1.7674e-03],\n",
            "          [-1.1688e-02,  1.0971e-02,  4.8540e-03, -2.3384e-02,  3.7864e-04],\n",
            "          [-2.5837e-02, -2.2900e-02, -1.0020e-02, -2.5614e-02,  2.6354e-03],\n",
            "          [-5.6256e-03,  1.5997e-02, -4.9814e-03, -2.1703e-02,  2.0002e-02],\n",
            "          [ 8.5921e-03, -2.2738e-02,  1.9563e-02,  6.8089e-03, -1.7342e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4591e-02, -2.2676e-02, -8.8334e-03,  6.9332e-03, -2.6697e-02],\n",
            "          [-1.3078e-02,  1.4273e-02,  1.4936e-02, -3.0419e-03, -1.1782e-02],\n",
            "          [-1.5968e-02, -2.6193e-02,  5.2845e-03,  7.5390e-03, -2.4393e-02],\n",
            "          [ 6.8409e-03, -7.8963e-03,  1.5865e-02,  3.0569e-02, -6.7514e-03],\n",
            "          [-1.6149e-02,  2.9132e-02,  2.1733e-03,  1.7311e-03,  2.8229e-03]],\n",
            "\n",
            "         [[-1.1713e-02,  2.4580e-02, -1.1660e-02,  3.2263e-03, -4.8841e-03],\n",
            "          [ 2.4624e-02,  9.9795e-03,  2.0694e-02,  8.6118e-04,  5.0932e-03],\n",
            "          [-7.0606e-03,  1.2041e-02, -1.4407e-02, -1.1312e-02, -7.4592e-03],\n",
            "          [-2.1182e-02, -1.1157e-02,  8.5106e-03, -1.1669e-02,  2.2897e-02],\n",
            "          [ 5.6943e-03,  2.4618e-02, -7.9109e-03,  1.8315e-02,  7.6967e-03]],\n",
            "\n",
            "         [[-1.6775e-02, -1.4548e-02, -1.9746e-02,  6.1296e-03, -3.7583e-03],\n",
            "          [-1.1616e-02, -1.0003e-02, -1.2860e-02,  2.3322e-02, -9.9104e-04],\n",
            "          [-2.0900e-02, -1.3139e-02,  3.2982e-04,  1.2326e-02,  1.4876e-02],\n",
            "          [-1.7415e-02, -1.9559e-02,  1.8319e-02, -1.2815e-03,  1.3543e-02],\n",
            "          [ 2.0854e-02,  3.3615e-04,  3.0609e-03, -1.7614e-02,  2.5234e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2836e-02, -7.1956e-03, -2.1470e-02, -1.4169e-02, -8.2298e-03],\n",
            "          [-7.6494e-04, -6.5461e-03,  7.3006e-03,  1.4335e-02, -5.7809e-03],\n",
            "          [-1.1704e-04,  1.8510e-02, -2.4615e-02,  3.7299e-03, -1.9791e-02],\n",
            "          [ 1.1970e-02, -2.2470e-02, -1.4240e-02,  1.1118e-02, -2.0110e-02],\n",
            "          [-2.6960e-03,  7.5480e-03, -2.3621e-02,  7.7485e-03, -4.7986e-03]],\n",
            "\n",
            "         [[-1.6615e-02,  1.6436e-02,  1.6696e-02,  2.6115e-02, -4.3059e-03],\n",
            "          [ 2.4262e-02,  9.2866e-03,  1.5415e-02,  1.8164e-02,  2.1521e-02],\n",
            "          [ 1.3335e-02, -1.4312e-02, -3.1548e-03,  2.5607e-02, -2.6999e-02],\n",
            "          [ 2.7900e-02,  2.5152e-02,  1.1634e-02,  1.6228e-02,  1.3734e-03],\n",
            "          [-1.3523e-02, -1.5401e-02,  2.3981e-02,  2.5135e-02,  1.0706e-02]],\n",
            "\n",
            "         [[ 6.6475e-03,  1.8706e-02, -1.0566e-02,  2.4996e-02, -6.0514e-03],\n",
            "          [-6.0629e-03, -1.6538e-02,  7.7041e-04, -1.4082e-02,  1.2721e-02],\n",
            "          [ 2.1775e-02, -1.3451e-02,  1.2963e-02, -2.2351e-02,  3.0976e-03],\n",
            "          [ 2.2596e-02,  1.2194e-02,  6.1938e-03,  1.1079e-02,  2.2427e-02],\n",
            "          [ 2.4589e-02,  1.5389e-03,  9.4903e-03,  1.7625e-02, -9.1354e-03]]]],\n",
            "       device='cuda:0')\n",
            "features.3.bias - parameter:\n",
            " tensor([ 8.6641e-03,  4.9990e-03, -1.2754e-02, -2.1838e-02, -1.4685e-02,\n",
            "         1.5054e-03,  1.3018e-03,  1.3381e-02,  7.3150e-03,  1.1688e-02,\n",
            "         2.4718e-02, -1.9850e-02,  1.8880e-02,  2.0920e-02,  5.2852e-03,\n",
            "        -6.4616e-03, -8.7727e-03,  9.8979e-03, -2.3006e-03, -2.0060e-02,\n",
            "         2.3675e-02,  1.4403e-02, -3.6020e-03, -2.0103e-02,  2.1876e-02,\n",
            "        -1.1410e-02, -1.2588e-02,  1.6999e-02,  4.2984e-05, -5.6751e-03,\n",
            "        -6.0669e-03, -7.3397e-04, -1.5552e-02,  1.2141e-02,  2.3093e-02,\n",
            "         1.5805e-02,  2.0557e-02,  1.2246e-02,  4.4858e-03,  4.0689e-03,\n",
            "         1.6216e-02,  2.8188e-03, -1.9625e-02,  1.8265e-02,  5.7649e-03,\n",
            "        -1.1701e-03, -1.4612e-02, -2.9578e-03, -2.7541e-03,  2.3150e-02,\n",
            "        -9.9043e-03,  2.3831e-02,  2.0473e-02,  1.0602e-02,  2.4223e-02,\n",
            "        -9.7625e-03, -1.6554e-02, -6.9323e-03, -2.8435e-03,  2.8251e-03,\n",
            "         1.6739e-02, -2.2189e-02,  7.0398e-04,  6.4580e-03, -1.7245e-02,\n",
            "        -3.1083e-03,  2.9765e-03,  1.5185e-02, -1.8059e-02, -2.4058e-02,\n",
            "        -1.3637e-02,  1.1213e-02,  4.6919e-03,  3.2692e-03, -5.4195e-03,\n",
            "        -2.1459e-02,  1.5113e-02, -1.1420e-02,  3.6531e-03,  1.0227e-02,\n",
            "        -1.1870e-02,  7.6521e-03,  1.7994e-02,  5.2612e-03, -5.9038e-03,\n",
            "        -1.4291e-02,  2.0362e-02,  4.6700e-03,  5.0389e-03,  9.6093e-03,\n",
            "        -2.3932e-02, -2.2663e-02, -4.1659e-03, -9.9493e-03,  1.6002e-02,\n",
            "        -2.4460e-02,  9.9744e-04,  2.3801e-02, -1.6200e-02, -1.5915e-02,\n",
            "         5.7483e-03,  5.4389e-03,  1.5714e-02,  1.8159e-02,  2.2446e-02,\n",
            "         2.4011e-02, -1.0525e-02,  2.3697e-02,  2.4391e-02,  1.3965e-02,\n",
            "        -1.4895e-02, -1.6537e-02,  2.4976e-02,  1.4287e-02, -1.6664e-02,\n",
            "        -1.2163e-02,  1.7205e-02,  1.2173e-02,  2.3657e-02, -6.3749e-03,\n",
            "        -2.0751e-02, -2.2382e-02, -1.2995e-02, -2.2506e-02,  1.8843e-02,\n",
            "        -1.0360e-02, -1.5479e-03, -1.1349e-02,  2.0925e-02,  1.3207e-02,\n",
            "         1.0578e-02, -3.6782e-03, -2.4031e-02, -2.5617e-03, -1.4946e-02,\n",
            "         1.6377e-02,  2.3939e-03,  1.1923e-03,  1.7057e-02,  4.4802e-03,\n",
            "        -1.1666e-02,  1.6579e-02, -2.3665e-02,  3.0346e-03,  2.2832e-02,\n",
            "        -7.6193e-03, -5.8053e-03,  1.7445e-02,  2.1524e-02,  1.5388e-02,\n",
            "        -1.8257e-02, -2.3210e-02, -1.3632e-02, -2.2129e-02, -2.4620e-02,\n",
            "        -1.5396e-02, -8.6840e-03, -1.8830e-02, -3.5158e-03,  1.5612e-02,\n",
            "        -5.4789e-03, -1.9448e-02,  2.0841e-02,  1.4738e-03, -2.2316e-03,\n",
            "        -2.2581e-02, -3.2118e-03,  1.6744e-02, -2.2140e-02, -9.0684e-03,\n",
            "        -1.8251e-02,  2.2306e-02,  2.4842e-02, -1.9443e-02, -1.1670e-02,\n",
            "         4.4678e-03, -1.8011e-02, -1.9627e-02, -6.4779e-03, -9.2817e-03,\n",
            "        -8.4705e-03,  7.1667e-03, -5.4848e-03, -2.5391e-03,  9.4505e-03,\n",
            "        -2.2323e-03,  1.3330e-02, -2.3549e-02, -1.5095e-03,  4.3169e-04,\n",
            "        -2.0220e-02,  1.7015e-02], device='cuda:0')\n",
            "features.6.weight - parameter:\n",
            " tensor([[[[-6.3716e-03,  1.3142e-02,  2.1356e-02],\n",
            "          [ 3.0792e-03,  1.6645e-02, -2.2846e-02],\n",
            "          [ 1.4697e-02,  1.6744e-02, -4.3410e-03]],\n",
            "\n",
            "         [[-1.4625e-02,  1.1085e-02, -1.2860e-02],\n",
            "          [-1.6985e-02, -1.7009e-02, -7.9371e-03],\n",
            "          [ 1.6186e-02,  1.4051e-02,  1.3094e-02]],\n",
            "\n",
            "         [[-1.1661e-02,  2.0409e-02, -9.5693e-03],\n",
            "          [-7.9471e-04,  2.1458e-02,  1.6874e-02],\n",
            "          [ 1.4426e-02, -2.3013e-02,  9.9969e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1632e-03, -1.0413e-02,  6.5420e-03],\n",
            "          [-8.3218e-03, -4.7534e-03,  7.0687e-03],\n",
            "          [ 8.9672e-04,  1.6235e-02, -1.2026e-02]],\n",
            "\n",
            "         [[ 2.2924e-02,  2.0407e-03,  1.1960e-02],\n",
            "          [ 4.0055e-03, -2.2990e-02,  2.1151e-04],\n",
            "          [ 1.8281e-02, -2.6668e-02,  4.4578e-03]],\n",
            "\n",
            "         [[-1.3015e-02, -6.1698e-03,  1.7883e-02],\n",
            "          [-5.6296e-03, -6.1915e-03, -8.5214e-03],\n",
            "          [ 2.4828e-02,  1.0075e-02, -6.3484e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.5401e-02,  1.9040e-02, -2.0342e-02],\n",
            "          [-1.6975e-02,  1.9704e-02,  3.7994e-03],\n",
            "          [ 9.4201e-03, -7.1948e-03,  1.2190e-02]],\n",
            "\n",
            "         [[ 1.0770e-02, -4.6805e-03,  2.0550e-02],\n",
            "          [ 2.0018e-02,  8.0712e-03, -7.8200e-03],\n",
            "          [-2.0792e-03, -1.9217e-02, -1.0818e-02]],\n",
            "\n",
            "         [[ 1.9195e-02,  1.7887e-03, -1.0222e-02],\n",
            "          [ 4.3338e-03,  1.7147e-02,  1.2852e-02],\n",
            "          [ 1.5815e-02, -7.6844e-03,  1.8312e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8758e-02,  1.9446e-02,  3.5012e-03],\n",
            "          [-5.2247e-03, -8.0736e-03, -1.3819e-02],\n",
            "          [ 8.5029e-03,  1.0550e-02, -1.1930e-03]],\n",
            "\n",
            "         [[-1.8627e-02,  1.6613e-02,  3.5323e-03],\n",
            "          [-5.8180e-03, -9.9999e-03,  2.4523e-02],\n",
            "          [-7.2847e-03,  1.8762e-02, -5.3365e-03]],\n",
            "\n",
            "         [[ 6.6205e-04,  5.1624e-03,  1.9507e-02],\n",
            "          [-2.2322e-02, -7.0662e-05,  1.5515e-02],\n",
            "          [-7.2840e-03, -1.8037e-02, -6.7186e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1272e-02,  1.4161e-02,  7.6768e-03],\n",
            "          [ 2.3304e-02, -1.2955e-02,  8.6665e-03],\n",
            "          [ 2.0095e-02,  3.0628e-03,  1.1969e-02]],\n",
            "\n",
            "         [[-1.4007e-03,  2.3837e-02,  1.3254e-03],\n",
            "          [ 2.4403e-02, -1.9913e-02,  3.0940e-04],\n",
            "          [ 1.5964e-02, -1.3070e-02,  1.0166e-03]],\n",
            "\n",
            "         [[-1.4434e-02, -5.8627e-03, -1.3977e-03],\n",
            "          [ 2.1581e-02,  1.6050e-02,  2.3877e-02],\n",
            "          [ 1.3399e-02, -9.9055e-03, -1.0861e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.9503e-03,  1.7644e-02,  8.0250e-03],\n",
            "          [ 4.7117e-03, -1.5748e-02, -2.3723e-02],\n",
            "          [-1.5598e-02,  4.4428e-03, -1.5771e-02]],\n",
            "\n",
            "         [[ 7.9746e-03,  2.4678e-02,  6.7645e-03],\n",
            "          [ 1.6785e-02, -4.2413e-03, -1.2774e-02],\n",
            "          [ 2.8714e-03,  1.0890e-02, -1.3108e-02]],\n",
            "\n",
            "         [[-5.8101e-03, -6.8594e-03, -4.2206e-03],\n",
            "          [ 5.3477e-03,  1.5972e-02,  6.5744e-03],\n",
            "          [ 1.1545e-02,  6.1781e-03, -1.9873e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3686e-02,  1.5462e-02, -2.1542e-02],\n",
            "          [ 1.5255e-02,  1.9304e-02, -2.0117e-02],\n",
            "          [ 1.2138e-02,  2.1944e-02,  2.0387e-03]],\n",
            "\n",
            "         [[-2.0142e-02,  2.1500e-02, -1.9081e-02],\n",
            "          [ 8.4177e-03, -2.0024e-02, -4.3338e-03],\n",
            "          [-1.7125e-02,  1.1867e-02, -5.1996e-03]],\n",
            "\n",
            "         [[ 2.1596e-02,  1.9681e-02, -9.8058e-03],\n",
            "          [-9.8958e-03,  1.4483e-02, -3.0659e-03],\n",
            "          [ 2.4342e-02, -1.5785e-02,  2.5924e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4345e-03,  2.0427e-02, -6.2391e-03],\n",
            "          [-1.3363e-02,  2.0067e-02, -1.4739e-02],\n",
            "          [ 1.8542e-02,  1.8302e-02, -1.0153e-02]],\n",
            "\n",
            "         [[-1.1829e-02, -1.8663e-02, -1.3369e-02],\n",
            "          [-2.2629e-02, -1.9877e-02, -1.8790e-02],\n",
            "          [ 1.5994e-02, -2.6408e-02,  1.3131e-04]],\n",
            "\n",
            "         [[-2.2141e-02,  6.3894e-03, -1.7917e-02],\n",
            "          [ 1.0760e-02,  1.9596e-02, -7.0273e-03],\n",
            "          [ 2.6641e-02,  1.0714e-02,  1.0730e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3977e-02, -2.0578e-02,  7.8059e-03],\n",
            "          [-1.2680e-02, -1.8871e-02,  3.9467e-03],\n",
            "          [ 1.9149e-02, -1.3695e-02,  1.6097e-02]],\n",
            "\n",
            "         [[ 2.1715e-02, -3.1244e-04, -1.1395e-03],\n",
            "          [ 1.6425e-02,  2.2414e-02,  2.0172e-03],\n",
            "          [ 4.6218e-03, -1.4055e-02, -9.9352e-03]],\n",
            "\n",
            "         [[ 1.5392e-02, -4.9880e-03,  1.0609e-02],\n",
            "          [ 1.2177e-02,  7.0917e-03,  5.3163e-03],\n",
            "          [-5.3257e-03, -6.3876e-03, -1.4376e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1725e-04, -1.3475e-02, -2.1524e-02],\n",
            "          [ 4.8910e-03, -4.9633e-03,  2.1623e-02],\n",
            "          [-9.6146e-04, -1.0797e-02,  1.1142e-02]],\n",
            "\n",
            "         [[ 2.6266e-03, -2.3424e-03, -1.8782e-02],\n",
            "          [-1.4476e-03,  2.2891e-02,  1.8937e-02],\n",
            "          [-4.4486e-03,  5.5983e-03,  6.9481e-03]],\n",
            "\n",
            "         [[ 6.0471e-03, -1.4966e-02, -1.1910e-02],\n",
            "          [ 2.2938e-02,  7.7063e-03,  2.2263e-02],\n",
            "          [-7.0524e-04, -1.0238e-02, -9.8247e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2985e-02, -1.3270e-02, -1.4373e-02],\n",
            "          [-1.8531e-02,  3.3800e-03,  1.5536e-02],\n",
            "          [-2.6618e-03, -1.9113e-02, -2.2812e-02]],\n",
            "\n",
            "         [[ 1.4544e-02,  2.6762e-03, -2.2346e-02],\n",
            "          [-5.1721e-03,  4.3389e-04,  1.6720e-02],\n",
            "          [-2.4271e-03, -1.3342e-02,  5.5306e-03]],\n",
            "\n",
            "         [[-1.6881e-02, -9.8194e-03, -1.8901e-02],\n",
            "          [ 1.2720e-02, -1.8675e-02,  2.1122e-02],\n",
            "          [ 1.7196e-02, -1.7612e-02,  1.8579e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8396e-02,  2.1080e-02,  1.1144e-03],\n",
            "          [ 2.2822e-02,  2.3297e-02, -1.5237e-03],\n",
            "          [ 1.1526e-02, -1.9792e-02, -1.9402e-02]],\n",
            "\n",
            "         [[ 2.2351e-02,  9.6858e-03, -2.0101e-02],\n",
            "          [ 1.9354e-02, -1.0159e-02, -1.5442e-02],\n",
            "          [ 3.8691e-03,  1.2309e-02,  1.8471e-04]],\n",
            "\n",
            "         [[ 1.8341e-02,  2.0562e-02, -9.0354e-03],\n",
            "          [-2.0068e-02, -2.1928e-02, -2.3910e-03],\n",
            "          [-8.3708e-03, -1.5890e-02,  3.8086e-03]]]], device='cuda:0')\n",
            "features.6.bias - parameter:\n",
            " tensor([ 1.0590e-02,  6.5787e-03,  1.9112e-02, -1.8011e-02, -1.0159e-02,\n",
            "        -1.0317e-02,  1.3669e-02,  1.4998e-02, -1.6190e-02, -3.4744e-03,\n",
            "        -1.8372e-02,  1.4777e-02,  8.6383e-03, -4.4711e-03, -1.7913e-02,\n",
            "        -1.5104e-03, -1.3283e-02,  1.3664e-03, -3.3109e-03, -2.2617e-02,\n",
            "         1.1186e-02, -1.7548e-02,  4.6648e-03,  1.3621e-02,  1.3134e-02,\n",
            "         4.0887e-03,  1.9153e-02, -2.0491e-02,  2.3028e-02, -1.4330e-02,\n",
            "         8.8391e-03, -1.5707e-03,  1.9008e-02,  4.9395e-03, -1.7569e-02,\n",
            "         8.7659e-04, -1.9936e-02, -1.5763e-02, -2.3675e-02, -6.8492e-04,\n",
            "         1.8650e-02,  6.5402e-03,  4.0567e-03,  1.9547e-02, -1.1571e-02,\n",
            "        -2.8581e-03,  6.8915e-03, -8.6252e-04,  1.2831e-02,  1.9823e-02,\n",
            "         1.8418e-02,  5.4164e-03, -1.6576e-02, -1.3533e-02,  8.8303e-04,\n",
            "         2.0794e-02,  2.1541e-02, -1.9120e-02,  1.0205e-02, -5.6798e-03,\n",
            "        -2.2277e-02, -2.5446e-03,  2.3440e-02,  6.6398e-03,  6.7804e-04,\n",
            "         1.3250e-02,  7.5237e-03,  2.0042e-02, -8.4710e-03,  9.9179e-03,\n",
            "        -1.0107e-02, -2.2885e-02,  2.2828e-02, -1.0565e-02,  8.0588e-03,\n",
            "        -5.5191e-03,  1.2449e-02,  1.9013e-02, -2.3397e-02, -9.1805e-03,\n",
            "        -2.1642e-02,  1.5861e-02,  1.0440e-02,  1.1345e-02,  8.8809e-03,\n",
            "        -2.3990e-02, -2.2746e-02,  1.1277e-02,  9.0689e-03, -9.4324e-03,\n",
            "         9.4165e-03, -1.2278e-02, -1.8432e-02, -1.3398e-03,  1.1725e-02,\n",
            "        -2.1747e-02, -9.3094e-03, -1.2363e-02, -1.7355e-02,  1.0828e-02,\n",
            "         2.2406e-02,  5.2004e-03,  6.0774e-03, -2.3479e-02, -2.2649e-02,\n",
            "         2.0703e-02,  1.3613e-02,  2.1147e-02, -1.3967e-02,  1.2420e-02,\n",
            "        -1.5966e-02,  6.1130e-03,  2.2260e-02,  1.8940e-02,  1.3315e-03,\n",
            "        -1.8246e-02, -2.1890e-02,  1.7680e-02,  2.2962e-02, -1.5853e-02,\n",
            "         3.8592e-03, -3.3953e-03,  1.9163e-02,  1.9414e-02, -7.6249e-03,\n",
            "         1.5909e-02, -1.1255e-02, -5.0651e-03, -2.0949e-02,  5.6545e-03,\n",
            "        -2.2523e-02,  1.4815e-02, -2.7185e-03, -7.7911e-05, -2.3361e-02,\n",
            "         1.5158e-02, -4.3010e-03,  2.1712e-02, -1.0732e-02, -4.3325e-03,\n",
            "        -5.7170e-03,  1.2553e-02, -3.0477e-03,  1.6052e-02, -5.5157e-03,\n",
            "         1.9052e-02,  1.9948e-02,  7.3835e-04, -1.6908e-02, -1.0152e-02,\n",
            "         1.7028e-02,  2.1746e-02,  1.8871e-02, -5.5322e-03,  1.4033e-02,\n",
            "        -4.5306e-03, -5.3385e-03,  1.9290e-02,  2.2493e-02,  1.8648e-02,\n",
            "         1.6973e-02, -9.8844e-03,  1.9647e-02, -2.4551e-03,  2.2933e-02,\n",
            "        -1.5823e-02, -1.7571e-02,  2.1537e-02,  7.8435e-03, -1.1902e-02,\n",
            "         2.0787e-04,  1.9051e-02, -5.1331e-03,  1.7836e-02, -2.1169e-02,\n",
            "        -2.0548e-02,  4.2770e-03,  1.4465e-02, -1.6239e-02, -8.3589e-03,\n",
            "         6.7201e-03, -9.7821e-03, -3.7051e-03, -4.6065e-03,  1.5687e-03,\n",
            "         1.8006e-02, -3.1803e-03,  6.2264e-03, -1.2288e-02,  1.6832e-02,\n",
            "         7.0248e-03, -1.9308e-02,  1.7343e-02, -4.5641e-03,  1.2183e-02,\n",
            "         1.6173e-02,  2.2787e-02,  1.2616e-02,  2.2865e-02, -5.2696e-03,\n",
            "         1.2838e-02,  8.8920e-03, -7.0559e-03, -1.5989e-02, -1.4848e-02,\n",
            "        -6.3119e-03, -1.1258e-02, -2.3245e-02,  1.8680e-02, -1.7754e-02,\n",
            "        -9.0588e-03,  5.2657e-03, -9.0481e-03,  8.2302e-03, -1.2447e-02,\n",
            "        -1.7231e-02,  8.9057e-03, -1.9520e-02,  2.2412e-02, -1.7601e-02,\n",
            "         1.3026e-02,  8.7013e-03,  1.5079e-02, -4.4086e-03,  1.1920e-02,\n",
            "        -1.3276e-02,  8.3857e-03, -1.0584e-03, -2.9748e-03, -1.0861e-02,\n",
            "        -1.4983e-02, -1.1081e-02,  2.6862e-03, -1.5972e-02, -2.9843e-03,\n",
            "        -8.1135e-03,  7.2487e-03, -4.7417e-03, -1.0106e-02, -9.8852e-03,\n",
            "         2.2749e-03,  1.0276e-03,  1.0125e-02,  6.3807e-04,  2.6439e-03,\n",
            "         1.9476e-02, -1.7983e-02,  2.2802e-02, -1.2624e-02, -7.2174e-03,\n",
            "         1.5542e-02,  1.7740e-02,  1.4860e-02,  1.2668e-03,  6.0006e-03,\n",
            "        -7.7016e-03,  2.2771e-02,  3.5053e-03,  1.8159e-02,  1.6006e-02,\n",
            "        -2.2048e-02, -1.2345e-03,  1.4268e-02, -6.9456e-03, -1.8260e-02,\n",
            "         4.1277e-03, -1.0784e-02,  1.8617e-02, -2.0532e-02,  2.3044e-02,\n",
            "         1.7206e-02,  4.1418e-03,  7.6053e-03,  1.0175e-02, -1.1302e-02,\n",
            "         2.1330e-02,  2.6209e-03, -5.8993e-03,  1.2734e-02, -1.4884e-03,\n",
            "         3.9884e-03, -7.6985e-03,  8.8137e-03, -4.8540e-03,  8.0418e-03,\n",
            "        -2.0724e-03, -1.8131e-02,  7.4935e-03, -5.9704e-03,  1.9211e-02,\n",
            "        -1.5891e-02,  1.5642e-02,  7.2263e-03,  3.4008e-03,  2.4828e-03,\n",
            "        -1.5744e-02, -1.2404e-02,  6.7122e-03,  5.3693e-03, -2.5664e-03,\n",
            "        -3.8020e-03, -2.2161e-02, -2.3222e-03,  1.5805e-02, -6.2280e-03,\n",
            "         4.1101e-03, -4.0783e-03, -7.5465e-03,  2.3126e-02,  8.9901e-03,\n",
            "         1.8705e-03,  5.3661e-03,  1.1881e-02, -4.2544e-03,  2.3658e-03,\n",
            "        -1.8772e-02, -7.2592e-03, -6.4798e-03, -1.3901e-02, -1.2231e-02,\n",
            "         5.9546e-03,  1.6631e-04,  2.4107e-02, -1.1128e-04, -1.6221e-02,\n",
            "        -5.1451e-03,  9.7849e-03,  2.1882e-02, -8.2632e-03, -1.2078e-02,\n",
            "        -6.0927e-03,  1.7540e-02, -3.4106e-03,  5.5704e-03, -6.3586e-03,\n",
            "         9.9425e-03, -2.0906e-02, -9.3212e-04, -9.9470e-03, -1.8082e-02,\n",
            "        -2.0036e-02,  1.4623e-02, -1.4236e-02, -1.7157e-02, -1.4043e-02,\n",
            "        -2.0371e-02,  2.0923e-02,  1.5514e-02, -1.9266e-03, -1.8079e-02,\n",
            "        -1.7092e-02, -1.9649e-02, -1.9783e-02,  2.3228e-02, -1.8745e-02,\n",
            "        -3.7789e-03,  8.5417e-03,  1.0250e-02,  1.5212e-02, -1.4912e-02,\n",
            "         4.5150e-03, -9.0145e-03,  1.6293e-02,  4.4908e-03, -4.1597e-03,\n",
            "         1.9584e-02, -2.0205e-02, -3.5636e-05, -4.2645e-03, -1.1457e-02,\n",
            "        -2.0142e-02,  9.7084e-03, -1.0306e-02, -2.3931e-02,  2.3526e-02,\n",
            "        -2.2250e-02,  1.3757e-02, -2.2260e-02, -1.4077e-02,  1.2041e-02,\n",
            "        -1.9300e-02,  1.0540e-02, -1.6714e-02, -7.0430e-03], device='cuda:0')\n",
            "features.8.weight - parameter:\n",
            " tensor([[[[-1.6078e-02, -1.0589e-02,  1.2899e-03],\n",
            "          [ 1.2945e-02, -1.3718e-02, -1.3796e-02],\n",
            "          [ 2.9275e-03,  1.5363e-02,  1.5144e-02]],\n",
            "\n",
            "         [[-8.7750e-03,  1.5264e-02, -7.1514e-03],\n",
            "          [-1.4622e-02,  1.2717e-02, -7.4459e-03],\n",
            "          [ 1.2362e-02,  3.2017e-03,  2.1171e-02]],\n",
            "\n",
            "         [[-1.0758e-02, -1.4403e-02, -1.0250e-02],\n",
            "          [-1.1454e-03,  4.7145e-03,  9.9296e-03],\n",
            "          [-2.0197e-03, -7.6047e-03,  2.0645e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.0106e-03,  1.3669e-02, -1.5488e-02],\n",
            "          [-1.6680e-02, -1.3452e-02,  7.5234e-04],\n",
            "          [ 2.5258e-03, -8.0679e-03, -3.7515e-03]],\n",
            "\n",
            "         [[ 1.3656e-02, -2.4848e-03, -1.6467e-02],\n",
            "          [-5.4680e-03,  1.6256e-02, -8.0956e-03],\n",
            "          [-1.6692e-02,  1.5369e-02,  1.3387e-02]],\n",
            "\n",
            "         [[-1.2902e-02,  2.8737e-03,  1.6964e-02],\n",
            "          [ 7.8533e-03,  6.7499e-03,  4.5121e-03],\n",
            "          [-5.2611e-03,  3.6339e-03,  1.5606e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8133e-03,  1.6470e-02,  1.4851e-02],\n",
            "          [ 1.6831e-02,  8.6293e-03, -1.5965e-02],\n",
            "          [-4.7099e-03,  1.1683e-03, -9.9975e-03]],\n",
            "\n",
            "         [[-1.2670e-03,  8.5671e-03, -1.1614e-03],\n",
            "          [ 1.2479e-02,  1.1824e-02, -5.4786e-03],\n",
            "          [-1.1430e-02,  1.0763e-02, -7.8290e-03]],\n",
            "\n",
            "         [[-2.5322e-03, -1.7019e-02,  1.1381e-03],\n",
            "          [-9.2243e-03,  1.2374e-03,  2.8557e-04],\n",
            "          [ 1.1240e-03, -4.4442e-03,  7.1060e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.3745e-03,  1.3087e-02, -1.3807e-02],\n",
            "          [-8.3081e-03,  1.3708e-02,  1.1691e-02],\n",
            "          [-1.5265e-02,  7.4310e-03,  3.4784e-03]],\n",
            "\n",
            "         [[-1.1707e-02, -1.3789e-03,  1.3431e-02],\n",
            "          [ 1.4314e-02, -3.4990e-03, -6.3202e-03],\n",
            "          [-1.0402e-03, -1.4660e-02, -1.5929e-02]],\n",
            "\n",
            "         [[-1.2210e-02,  1.4012e-04, -1.1179e-02],\n",
            "          [ 1.1295e-02,  6.0741e-03,  3.3546e-04],\n",
            "          [ 1.0799e-02,  1.6608e-02, -4.5775e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5651e-02, -7.8353e-03, -9.1748e-03],\n",
            "          [ 1.5170e-03, -1.1273e-02,  9.7645e-04],\n",
            "          [-5.9998e-03,  1.2536e-02,  1.7439e-02]],\n",
            "\n",
            "         [[ 4.2794e-03,  1.2969e-02, -8.9171e-03],\n",
            "          [ 1.6822e-02,  6.6439e-03,  1.3862e-02],\n",
            "          [ 1.0523e-02, -4.2100e-03, -1.6485e-02]],\n",
            "\n",
            "         [[ 1.4780e-02, -1.1912e-02,  1.1432e-02],\n",
            "          [ 5.7444e-03,  8.9913e-03, -5.9290e-03],\n",
            "          [-2.8970e-03,  1.0209e-02,  1.7916e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0852e-03, -1.1425e-02, -1.9596e-02],\n",
            "          [ 7.7590e-03,  1.5400e-02, -1.1434e-02],\n",
            "          [-8.9857e-03,  1.8261e-02, -3.4003e-03]],\n",
            "\n",
            "         [[ 8.7434e-03,  1.3382e-03,  1.6083e-02],\n",
            "          [ 1.4512e-02,  7.4473e-03,  1.2760e-02],\n",
            "          [-9.3395e-03,  6.3660e-03,  9.3773e-03]],\n",
            "\n",
            "         [[ 5.5215e-04, -4.5272e-03, -1.6672e-02],\n",
            "          [ 9.3714e-03, -1.6743e-02,  2.9052e-03],\n",
            "          [ 5.3286e-03, -1.0696e-03,  1.0159e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.3009e-03,  1.8761e-03,  1.7014e-02],\n",
            "          [ 1.0837e-02, -7.1626e-03,  1.0267e-02],\n",
            "          [-1.2157e-02,  4.5875e-03, -2.1176e-02]],\n",
            "\n",
            "         [[-8.0739e-03,  6.6880e-03,  1.4848e-02],\n",
            "          [ 6.4889e-03,  8.9254e-03,  4.6995e-03],\n",
            "          [ 1.1100e-02, -5.9754e-03, -1.7389e-02]],\n",
            "\n",
            "         [[ 6.6967e-03,  1.5196e-02,  1.6074e-02],\n",
            "          [ 9.5491e-03,  1.9109e-03,  7.1733e-03],\n",
            "          [-1.6633e-02, -1.6475e-02, -1.5614e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3668e-02,  8.8281e-03,  4.3589e-03],\n",
            "          [-1.4769e-02, -9.4886e-03, -4.0827e-03],\n",
            "          [ 1.1844e-02, -3.6147e-05, -5.7276e-03]],\n",
            "\n",
            "         [[-1.2753e-02,  4.4837e-03,  6.6175e-03],\n",
            "          [ 9.9597e-03,  1.2268e-02,  1.1815e-02],\n",
            "          [ 4.5659e-03, -7.6264e-03,  1.2286e-02]],\n",
            "\n",
            "         [[ 1.2230e-02,  1.1581e-02, -1.4744e-02],\n",
            "          [ 6.3169e-03, -1.3507e-02,  2.7366e-03],\n",
            "          [-1.1001e-02,  5.9660e-03, -5.7369e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1061e-02,  1.1146e-02,  1.6321e-02],\n",
            "          [-4.4628e-04,  1.2300e-02, -1.3327e-03],\n",
            "          [-1.3977e-02,  8.3564e-03,  3.9703e-03]],\n",
            "\n",
            "         [[ 5.4087e-03, -1.0542e-02,  7.6162e-03],\n",
            "          [ 2.3394e-03,  8.7096e-03, -7.4468e-03],\n",
            "          [ 1.2476e-02,  6.2452e-03, -1.4118e-02]],\n",
            "\n",
            "         [[-1.2077e-02,  1.3587e-02,  7.3101e-03],\n",
            "          [-1.3184e-02, -8.6886e-03,  1.2822e-02],\n",
            "          [ 2.2140e-03, -1.2871e-02, -9.6393e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6213e-02,  4.4607e-05, -8.3198e-03],\n",
            "          [-8.0482e-03, -1.6174e-02,  1.3178e-02],\n",
            "          [ 7.4539e-03,  1.6241e-02,  1.2046e-02]],\n",
            "\n",
            "         [[ 4.1569e-04,  5.6248e-03,  9.3251e-03],\n",
            "          [ 1.0809e-02, -5.4343e-03, -1.3771e-02],\n",
            "          [ 1.4093e-02, -4.7763e-03,  1.4446e-02]],\n",
            "\n",
            "         [[-4.6130e-03, -1.1313e-02, -1.5702e-02],\n",
            "          [ 2.1143e-03, -5.9913e-03, -1.1132e-03],\n",
            "          [-7.3954e-03,  1.5326e-02, -1.1761e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.6717e-03, -2.5379e-03,  1.3449e-02],\n",
            "          [ 2.8635e-03,  8.9079e-03,  3.7100e-03],\n",
            "          [ 8.0748e-03,  1.2607e-02,  1.0392e-02]],\n",
            "\n",
            "         [[ 1.0094e-02,  4.9297e-04,  7.6835e-03],\n",
            "          [-2.2669e-04,  1.1760e-02,  5.0490e-03],\n",
            "          [-3.1131e-03,  1.5623e-02, -2.4848e-03]],\n",
            "\n",
            "         [[-1.5577e-02,  1.1313e-02, -1.2043e-02],\n",
            "          [-9.6824e-03,  7.4833e-03,  8.3445e-03],\n",
            "          [ 1.0814e-02, -1.0018e-02, -9.0023e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1656e-02, -1.4172e-02,  9.9750e-03],\n",
            "          [ 2.7471e-03, -1.0861e-02,  8.0981e-03],\n",
            "          [-1.2267e-02,  1.1629e-02,  9.7747e-03]],\n",
            "\n",
            "         [[-1.4385e-02, -8.6384e-03, -6.9498e-03],\n",
            "          [-2.2873e-03,  1.6603e-02, -4.3561e-03],\n",
            "          [-1.6408e-02, -1.4387e-02,  9.9539e-03]],\n",
            "\n",
            "         [[ 6.0279e-03, -1.9128e-03, -1.2876e-02],\n",
            "          [-1.5894e-02, -1.3497e-04, -8.2370e-03],\n",
            "          [-9.3729e-03,  1.3435e-02, -1.2662e-02]]]], device='cuda:0')\n",
            "features.8.bias - parameter:\n",
            " tensor([ 1.2485e-02, -1.4746e-02,  1.5272e-02,  7.1679e-03, -2.8407e-03,\n",
            "        -8.6998e-03, -6.7710e-03,  2.2512e-03, -3.3539e-03,  8.0333e-03,\n",
            "        -8.9713e-03,  1.3462e-02,  6.6532e-04,  4.5794e-03, -7.0087e-03,\n",
            "        -4.5170e-03,  9.3925e-04,  3.8292e-03,  1.4145e-02, -8.9061e-03,\n",
            "        -3.9558e-03, -1.4451e-02, -1.6231e-02,  6.1955e-03,  1.2201e-02,\n",
            "        -1.0509e-02, -1.1122e-03,  5.3435e-03,  1.5001e-02, -6.4676e-03,\n",
            "        -8.6470e-03,  8.5389e-03, -1.5792e-03, -2.1293e-03,  1.0030e-02,\n",
            "         3.3478e-03,  4.0032e-03,  2.5983e-03, -1.5593e-02,  5.0243e-03,\n",
            "         7.5497e-03,  5.0354e-03,  1.2395e-02, -1.6599e-02, -1.2447e-02,\n",
            "         8.6327e-03, -1.4418e-02,  6.3961e-03,  1.2134e-02, -9.5028e-03,\n",
            "        -1.2305e-02,  2.0731e-03, -2.7459e-03, -1.8261e-03,  5.2317e-03,\n",
            "        -1.6202e-02, -1.3500e-02, -1.2625e-02, -2.1065e-03, -1.2741e-02,\n",
            "         1.0452e-02, -1.9735e-03,  1.3381e-03, -1.4841e-02,  1.0377e-02,\n",
            "         6.6822e-03, -4.3688e-03,  9.6900e-03, -1.1748e-02, -7.0251e-03,\n",
            "         8.9707e-03, -1.5302e-02,  1.3255e-02,  1.2249e-02, -7.5720e-03,\n",
            "        -6.0790e-03,  5.6893e-03, -1.5729e-02, -1.5547e-02, -8.4769e-03,\n",
            "         8.5235e-03,  3.0092e-03, -1.0248e-02, -1.8198e-04, -8.6862e-03,\n",
            "         6.0999e-03, -1.5702e-02,  1.4315e-02,  3.5916e-03,  2.7685e-03,\n",
            "         1.1980e-02,  1.6272e-02,  4.7811e-03, -3.9970e-03,  1.0376e-02,\n",
            "         6.0822e-03, -1.0599e-02, -7.5563e-03, -3.2239e-03,  1.0803e-02,\n",
            "        -3.3992e-03,  2.2645e-03,  1.6279e-02,  8.4542e-03,  1.4755e-02,\n",
            "         9.7069e-03, -1.3771e-02, -7.1193e-03,  2.5255e-03,  9.9228e-03,\n",
            "        -1.1947e-02,  3.7516e-04, -1.3903e-02, -1.1081e-02, -4.3942e-03,\n",
            "        -8.6380e-03,  6.4303e-03,  1.0262e-03, -1.0936e-02,  3.4092e-03,\n",
            "         1.2365e-02,  1.4553e-02, -9.2736e-03, -1.3072e-03, -1.1190e-02,\n",
            "         4.6899e-04, -1.6339e-02,  6.1780e-03, -3.3537e-03, -6.8234e-03,\n",
            "        -1.5006e-02,  1.6352e-02,  5.3438e-04,  7.7479e-03, -8.6924e-03,\n",
            "         1.6799e-02,  4.1925e-03, -1.4686e-02, -6.7365e-03, -1.0978e-02,\n",
            "         1.4615e-02,  1.2794e-03, -1.1254e-03, -5.0559e-05, -1.3232e-02,\n",
            "        -9.0603e-03, -8.8391e-04, -7.0317e-03,  3.4440e-03,  7.9504e-03,\n",
            "        -8.7273e-03, -1.5212e-02,  1.4813e-02, -2.5805e-03, -1.6740e-02,\n",
            "        -9.7095e-03,  4.6085e-03,  1.9731e-03, -6.1707e-03,  2.3871e-03,\n",
            "        -4.0609e-03,  4.9146e-03,  5.3339e-03,  9.4465e-03, -1.4492e-02,\n",
            "        -2.2986e-03,  3.2082e-03,  1.1427e-02,  3.8681e-03,  1.1349e-02,\n",
            "        -3.5623e-03, -1.6481e-03, -2.5246e-03,  7.3790e-04,  9.7085e-03,\n",
            "        -7.4640e-03,  1.3559e-02,  1.5751e-02,  4.1654e-03,  1.4676e-02,\n",
            "         1.6979e-02,  1.4552e-02, -1.5863e-03, -4.8230e-03,  1.0859e-02,\n",
            "        -1.0402e-02, -7.1279e-03, -1.0953e-02, -7.5875e-03, -9.3937e-03,\n",
            "         8.8068e-03,  4.9724e-03, -5.7798e-04,  3.9690e-03,  3.0973e-03,\n",
            "         1.3651e-02,  9.4505e-03,  6.9563e-03,  1.0359e-02,  7.4765e-03,\n",
            "        -1.5310e-02,  8.7608e-03,  4.4759e-03,  5.3966e-03,  1.0513e-02,\n",
            "        -4.3472e-04, -1.9799e-03, -1.6468e-02, -7.4942e-03, -7.3173e-03,\n",
            "        -5.3224e-03,  1.5425e-02, -1.5829e-02,  6.0274e-03,  3.3902e-04,\n",
            "         8.4347e-03, -2.2695e-03,  5.0249e-03,  1.2928e-02, -3.8767e-03,\n",
            "         6.2444e-03,  8.1693e-03, -1.6769e-02,  1.4065e-02, -1.1434e-02,\n",
            "         1.2390e-02,  2.1593e-04,  3.9204e-03,  1.1341e-02, -1.5426e-03,\n",
            "         2.0359e-04, -5.4847e-03,  4.4238e-03, -1.0161e-02,  1.1693e-02,\n",
            "        -8.4659e-04, -1.6192e-02, -2.2655e-03,  1.0049e-02,  2.9352e-03,\n",
            "         1.2044e-02, -1.4916e-02, -1.1787e-02,  6.8258e-03, -5.8660e-03,\n",
            "         1.1703e-03,  1.4749e-02,  4.7677e-04, -1.3972e-02, -1.5753e-02,\n",
            "         1.4569e-02, -3.6844e-03, -6.6193e-03,  7.1903e-03, -1.2183e-02,\n",
            "        -1.1473e-02], device='cuda:0')\n",
            "features.10.weight - parameter:\n",
            " tensor([[[[-1.6685e-03,  2.0222e-02, -7.5729e-03],\n",
            "          [ 1.7235e-02,  1.7817e-02,  1.0622e-03],\n",
            "          [-1.2406e-02,  1.5540e-02,  5.9753e-03]],\n",
            "\n",
            "         [[-1.3900e-02,  1.1526e-02,  1.1560e-02],\n",
            "          [-2.1035e-02,  1.7733e-02, -9.6242e-03],\n",
            "          [ 1.6560e-02, -1.0348e-02, -1.6964e-02]],\n",
            "\n",
            "         [[ 5.2033e-03,  1.1433e-02, -1.2780e-02],\n",
            "          [ 7.0479e-03,  2.8850e-03, -1.4641e-02],\n",
            "          [-3.0753e-04, -1.7629e-02,  7.1690e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1608e-02,  6.1353e-03, -1.2725e-02],\n",
            "          [-8.4358e-04,  2.4462e-02, -1.3307e-02],\n",
            "          [ 1.4728e-02,  1.6155e-02, -8.7666e-03]],\n",
            "\n",
            "         [[-5.3134e-03,  1.1959e-02,  1.5707e-02],\n",
            "          [ 6.7598e-04, -2.2563e-03, -2.8087e-03],\n",
            "          [-3.2545e-03,  1.2081e-02,  1.6115e-02]],\n",
            "\n",
            "         [[-1.9867e-02,  7.2108e-03, -1.0749e-02],\n",
            "          [-1.2587e-02, -2.0052e-02, -4.3909e-03],\n",
            "          [ 1.3344e-02,  1.6774e-02,  9.7205e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4672e-02,  5.7275e-03,  1.6306e-02],\n",
            "          [ 2.1330e-02, -1.1410e-02, -2.0682e-02],\n",
            "          [ 1.6516e-02, -5.4673e-03,  3.2693e-03]],\n",
            "\n",
            "         [[ 1.6284e-02,  6.0239e-03,  1.7731e-02],\n",
            "          [ 2.0720e-02, -2.1952e-02, -1.4444e-02],\n",
            "          [-4.3236e-03, -7.9740e-03,  1.6895e-02]],\n",
            "\n",
            "         [[ 9.9470e-03, -1.9593e-02,  1.4118e-02],\n",
            "          [ 5.3044e-03, -2.1361e-02, -1.5186e-02],\n",
            "          [-2.4235e-04,  1.4120e-02,  1.2641e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6390e-02,  1.4422e-02, -1.3414e-02],\n",
            "          [ 1.8234e-02,  1.1339e-02, -2.1851e-02],\n",
            "          [-1.1251e-02,  2.6160e-03, -5.7836e-03]],\n",
            "\n",
            "         [[ 8.6923e-03, -1.1286e-02,  1.2533e-02],\n",
            "          [ 9.7813e-03, -1.0671e-03,  1.7545e-02],\n",
            "          [-1.2322e-02, -1.0121e-02,  2.8917e-02]],\n",
            "\n",
            "         [[-1.9774e-02, -9.5053e-03, -3.6117e-03],\n",
            "          [-9.8944e-03,  4.7971e-04, -3.4665e-04],\n",
            "          [ 2.0270e-02, -3.2598e-03, -5.9458e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.9288e-03, -5.7090e-03, -1.2163e-02],\n",
            "          [-1.2880e-03,  6.2680e-03,  1.7281e-02],\n",
            "          [-1.3984e-02,  1.6644e-02,  2.2377e-02]],\n",
            "\n",
            "         [[-7.6035e-03, -3.4919e-03, -2.0796e-02],\n",
            "          [ 1.8523e-02,  1.9653e-02, -1.5714e-02],\n",
            "          [ 2.2597e-02,  3.6004e-03, -1.7228e-02]],\n",
            "\n",
            "         [[ 5.6069e-03,  6.3270e-03,  1.3582e-02],\n",
            "          [-1.3907e-04,  1.6444e-02, -6.5887e-03],\n",
            "          [ 1.0937e-02, -9.8351e-03, -5.1294e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4832e-02, -8.8880e-03,  1.5397e-02],\n",
            "          [ 1.9339e-02, -2.5308e-02,  1.0376e-02],\n",
            "          [ 2.1225e-02, -4.6195e-03,  2.2817e-02]],\n",
            "\n",
            "         [[ 1.3473e-02,  8.1988e-03,  2.5268e-03],\n",
            "          [-1.8780e-02,  5.4951e-03, -2.4730e-02],\n",
            "          [ 1.1544e-02, -1.0702e-02,  8.8013e-03]],\n",
            "\n",
            "         [[-1.1213e-02, -5.1241e-03, -7.5152e-03],\n",
            "          [ 3.3285e-03, -7.4712e-03,  4.3346e-04],\n",
            "          [-1.5254e-02,  1.4423e-02, -1.3141e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0431e-02, -3.6727e-03,  1.4965e-02],\n",
            "          [ 2.1727e-03,  1.4966e-02, -1.0873e-02],\n",
            "          [ 1.7860e-02, -1.4807e-02,  3.5182e-03]],\n",
            "\n",
            "         [[ 1.1142e-03,  1.4415e-02,  6.7798e-03],\n",
            "          [ 1.8250e-02, -8.5902e-03, -1.5441e-03],\n",
            "          [-1.5483e-02, -1.1530e-02,  1.8580e-02]],\n",
            "\n",
            "         [[ 1.5498e-02, -8.2596e-03, -1.7722e-02],\n",
            "          [-1.4171e-02,  8.3415e-03,  2.5513e-03],\n",
            "          [ 2.1580e-02,  8.7508e-03, -1.9147e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2645e-02, -1.1729e-02,  1.3963e-02],\n",
            "          [-2.8146e-02, -2.9564e-02,  2.1068e-02],\n",
            "          [ 4.9263e-03, -1.1844e-02, -1.5821e-02]],\n",
            "\n",
            "         [[ 7.9859e-03,  1.5210e-02, -2.3629e-03],\n",
            "          [ 1.1171e-02,  4.7504e-03,  8.0381e-03],\n",
            "          [ 1.3429e-02,  7.9286e-03,  1.2868e-03]],\n",
            "\n",
            "         [[ 1.7818e-02,  3.0182e-03,  7.6561e-03],\n",
            "          [ 1.0761e-02,  1.9607e-02,  1.5055e-02],\n",
            "          [-3.9451e-03,  1.1631e-02,  1.8288e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.2987e-03, -1.7302e-02,  1.9051e-02],\n",
            "          [-1.5864e-04, -2.0302e-02,  1.0516e-02],\n",
            "          [-4.5672e-03,  1.8137e-02,  1.5725e-02]],\n",
            "\n",
            "         [[-1.5418e-02, -8.7451e-03,  9.7035e-03],\n",
            "          [ 1.7514e-02,  1.9221e-02,  1.3221e-02],\n",
            "          [ 6.5240e-03,  4.1196e-04,  2.3178e-03]],\n",
            "\n",
            "         [[-1.2874e-02, -1.6789e-02, -3.9405e-03],\n",
            "          [-1.2370e-02, -1.8199e-02,  1.4711e-02],\n",
            "          [-1.5491e-02, -7.5918e-03, -2.5665e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.5345e-03, -8.3131e-03, -2.0852e-02],\n",
            "          [ 1.6970e-02, -1.3328e-02, -4.3890e-03],\n",
            "          [ 1.1785e-02,  1.0115e-02,  2.0618e-02]],\n",
            "\n",
            "         [[-9.7929e-03,  1.8371e-03, -7.2901e-03],\n",
            "          [-2.0416e-02, -8.2162e-03,  3.9997e-03],\n",
            "          [-7.3113e-03, -1.2362e-02, -5.0333e-03]],\n",
            "\n",
            "         [[-1.1345e-02,  5.3186e-03, -1.7150e-02],\n",
            "          [ 1.9570e-03, -9.9441e-03,  1.1237e-02],\n",
            "          [-1.8225e-02,  1.7001e-02, -1.6030e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2923e-03, -1.9224e-02, -1.1665e-02],\n",
            "          [ 5.8017e-03,  4.1182e-03, -1.3557e-02],\n",
            "          [ 1.5745e-02,  1.2357e-02,  9.0863e-03]],\n",
            "\n",
            "         [[-1.3355e-03,  1.9887e-02, -1.5377e-02],\n",
            "          [-2.2868e-02, -6.2946e-03,  1.2653e-02],\n",
            "          [ 2.4283e-03, -6.3338e-03, -1.6600e-02]],\n",
            "\n",
            "         [[-1.6589e-02, -1.9802e-02, -1.3174e-02],\n",
            "          [ 1.7182e-02, -8.2527e-03, -6.6628e-03],\n",
            "          [-9.8550e-03, -3.5458e-03,  1.9453e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3219e-02,  4.5028e-03, -2.0192e-02],\n",
            "          [-6.2424e-03, -1.5921e-02,  1.8398e-02],\n",
            "          [-1.8315e-02, -3.5196e-04, -1.8478e-02]],\n",
            "\n",
            "         [[ 2.3595e-03, -1.5208e-03,  1.4189e-02],\n",
            "          [ 1.0746e-02, -8.2546e-03, -2.2194e-02],\n",
            "          [-8.8743e-03, -1.8139e-02,  7.4296e-03]],\n",
            "\n",
            "         [[-1.8304e-05,  1.3625e-04, -5.8473e-03],\n",
            "          [-1.6472e-02,  2.0187e-02, -1.6605e-02],\n",
            "          [-1.9439e-03, -1.9480e-02, -1.9710e-02]]]], device='cuda:0')\n",
            "features.10.bias - parameter:\n",
            " tensor([ 1.9468e-02,  1.9703e-02, -4.2895e-03, -1.9420e-02, -1.2694e-02,\n",
            "        -1.3160e-02, -5.9958e-03, -1.8439e-02, -1.7963e-02, -5.6470e-03,\n",
            "        -5.4168e-03,  1.1105e-02, -6.4225e-03, -4.1282e-03,  9.3631e-04,\n",
            "        -3.4113e-03, -1.6176e-03, -1.0418e-02,  2.0006e-02,  1.9565e-02,\n",
            "        -1.6940e-02,  4.1985e-04,  1.9134e-02,  1.0680e-02,  2.1774e-05,\n",
            "        -1.0395e-02, -1.0299e-02, -1.3216e-02,  2.7768e-03,  1.3956e-02,\n",
            "        -1.1382e-02, -2.7670e-03,  1.2719e-02, -4.0538e-03,  6.5421e-03,\n",
            "         7.6799e-04,  5.7244e-03,  1.7319e-02,  2.1798e-03,  1.5407e-02,\n",
            "         1.7010e-02,  4.3682e-03, -4.2305e-03,  1.1867e-02,  1.8202e-02,\n",
            "        -9.2806e-03,  1.0953e-02, -5.5820e-03, -2.0615e-02, -5.4927e-03,\n",
            "         2.4484e-03,  1.2232e-02, -1.2068e-02, -1.0187e-02, -3.6815e-03,\n",
            "        -1.6143e-02,  2.9148e-03, -5.4648e-03, -1.4882e-02, -6.1457e-03,\n",
            "        -1.4753e-02,  1.5375e-02,  1.3195e-02,  3.2029e-04, -7.1985e-04,\n",
            "        -1.3079e-02, -1.8177e-02,  1.2498e-02, -6.7825e-03, -8.1881e-03,\n",
            "         1.9534e-02,  1.5235e-02,  1.2969e-02, -1.8397e-03,  9.4899e-03,\n",
            "         8.3871e-03, -1.5476e-02,  1.1826e-02,  6.9546e-03,  1.5440e-02,\n",
            "        -4.6974e-03,  8.7026e-03, -1.1046e-02, -4.9374e-03,  1.9965e-02,\n",
            "         5.1018e-03, -1.1945e-02,  2.5928e-03,  1.8492e-02,  2.6204e-03,\n",
            "        -1.9454e-02,  2.6220e-03,  1.8646e-02,  1.0221e-04,  2.0209e-03,\n",
            "         1.0953e-02,  1.1877e-02, -1.1358e-03,  1.0369e-02,  1.2376e-02,\n",
            "        -9.5586e-03,  1.1809e-02, -1.3321e-02,  6.9110e-03,  2.8854e-03,\n",
            "         3.6442e-03,  1.6383e-02, -3.2227e-03,  3.1682e-04, -2.2623e-03,\n",
            "         1.1228e-02,  1.2216e-02,  6.4793e-03, -1.3874e-02,  3.8217e-04,\n",
            "        -1.8253e-02, -1.4597e-02, -3.3454e-03,  2.8151e-03, -1.2203e-03,\n",
            "         1.9776e-02, -1.0510e-02, -4.2121e-03, -1.6036e-02,  2.0345e-02,\n",
            "        -1.6600e-02,  1.1798e-02, -1.9396e-03,  7.6476e-03, -1.9215e-02,\n",
            "        -1.4814e-02, -1.5431e-02,  5.0702e-03,  6.1025e-03,  4.7303e-03,\n",
            "         1.6814e-02,  6.3356e-03, -1.9651e-02, -1.9217e-02, -1.4299e-02,\n",
            "        -3.4263e-03, -5.8709e-03,  1.7211e-02, -1.2313e-02, -1.9817e-02,\n",
            "        -2.0669e-02,  8.8801e-04,  5.0398e-03,  1.2995e-02, -3.7665e-04,\n",
            "         7.7432e-03,  1.4644e-02, -1.3077e-02,  1.6732e-02,  4.7211e-03,\n",
            "        -1.5438e-02, -6.7783e-03, -1.7932e-02, -6.2639e-04,  6.6917e-03,\n",
            "         1.4359e-02, -1.6752e-03, -4.9115e-03, -1.9512e-02,  2.4041e-03,\n",
            "         1.9617e-02, -1.8171e-02, -1.9235e-03, -2.0583e-02,  1.4761e-02,\n",
            "         7.1344e-03,  2.5579e-04, -1.2708e-02, -6.9515e-03,  1.5043e-02,\n",
            "        -2.2391e-03,  3.0078e-03, -7.6178e-03,  1.0759e-02, -1.2559e-02,\n",
            "         3.9296e-04, -6.5056e-03,  1.8826e-02,  6.3554e-03, -1.8370e-02,\n",
            "         1.4625e-02, -2.0781e-02,  1.6187e-04,  1.5280e-03, -3.6446e-03,\n",
            "         1.8669e-02, -1.8921e-02, -1.3200e-02, -1.1955e-02, -1.2979e-03,\n",
            "         3.2653e-03, -7.0299e-03,  7.2333e-03,  1.5829e-02, -1.8888e-02,\n",
            "        -1.7723e-02, -1.6052e-02,  1.4083e-02,  1.9824e-02, -8.7734e-03,\n",
            "         9.7488e-04,  1.0727e-02, -1.5931e-02,  1.2318e-03, -1.1343e-02,\n",
            "         1.5367e-02, -1.9136e-02, -1.2668e-02, -4.5881e-03, -1.1575e-02,\n",
            "         1.1900e-02, -2.8241e-03,  1.1268e-02,  1.2617e-02,  1.3750e-02,\n",
            "        -3.3363e-03, -1.7803e-02, -5.5703e-03,  1.6050e-02, -4.3207e-03,\n",
            "        -1.5031e-02,  3.1464e-03,  1.7318e-02, -6.2695e-03,  6.7978e-03,\n",
            "        -6.5333e-04, -1.1637e-02,  1.3146e-02,  1.1716e-02,  1.0383e-02,\n",
            "        -6.9809e-03,  7.3221e-03, -6.9273e-03, -9.6401e-03,  3.2335e-03,\n",
            "         9.6879e-03,  1.2123e-03, -1.2309e-02,  1.7710e-02, -1.5945e-02,\n",
            "         3.7018e-03, -1.0187e-02,  1.3557e-02, -8.4542e-03, -9.4611e-03,\n",
            "         1.1221e-02, -6.9221e-03,  6.8463e-03, -1.7970e-02,  4.6802e-03,\n",
            "        -1.2610e-02], device='cuda:0')\n",
            "classifier.1.weight - parameter:\n",
            " tensor([[ 0.0090, -0.0029,  0.0042,  ...,  0.0015,  0.0095,  0.0087],\n",
            "        [-0.0023,  0.0045,  0.0147,  ...,  0.0112,  0.0152,  0.0175],\n",
            "        [ 0.0210, -0.0081, -0.0069,  ..., -0.0059,  0.0015, -0.0109],\n",
            "        ...,\n",
            "        [ 0.0147, -0.0009, -0.0084,  ...,  0.0203, -0.0155,  0.0167],\n",
            "        [ 0.0143,  0.0196,  0.0036,  ..., -0.0015, -0.0176,  0.0152],\n",
            "        [ 0.0190, -0.0136,  0.0039,  ...,  0.0041,  0.0168,  0.0119]],\n",
            "       device='cuda:0')\n",
            "classifier.1.bias - parameter:\n",
            " tensor([ 0.0208, -0.0055,  0.0059,  ...,  0.0191,  0.0088, -0.0124],\n",
            "       device='cuda:0')\n",
            "classifier.4.weight - parameter:\n",
            " tensor([[ 0.0098, -0.0020, -0.0081,  ..., -0.0019, -0.0014, -0.0049],\n",
            "        [ 0.0044,  0.0009, -0.0066,  ...,  0.0001, -0.0015, -0.0109],\n",
            "        [-0.0136, -0.0073,  0.0010,  ...,  0.0100, -0.0114, -0.0032],\n",
            "        ...,\n",
            "        [-0.0025, -0.0040,  0.0146,  ..., -0.0030, -0.0116, -0.0087],\n",
            "        [-0.0068, -0.0015, -0.0137,  ..., -0.0087, -0.0104,  0.0080],\n",
            "        [-0.0121, -0.0015, -0.0051,  ..., -0.0075,  0.0069,  0.0051]],\n",
            "       device='cuda:0')\n",
            "classifier.4.bias - parameter:\n",
            " tensor([ 0.0092,  0.0117,  0.0112,  ..., -0.0023, -0.0034,  0.0005],\n",
            "       device='cuda:0')\n",
            "classifier.6.weight - parameter:\n",
            " tensor([[ 0.0064,  0.0011,  0.0133,  ..., -0.0192, -0.0014,  0.0122],\n",
            "        [ 0.0048, -0.0121, -0.0172,  ...,  0.0182,  0.0052,  0.0111],\n",
            "        [-0.0107, -0.0062,  0.0015,  ..., -0.0038,  0.0178,  0.0037],\n",
            "        ...,\n",
            "        [ 0.0013,  0.0245,  0.0023,  ..., -0.0010,  0.0159, -0.0114],\n",
            "        [-0.0241, -0.0152,  0.0006,  ...,  0.0064, -0.0154, -0.0127],\n",
            "        [ 0.0036,  0.0085, -0.0100,  ..., -0.0021, -0.0043, -0.0040]],\n",
            "       device='cuda:0')\n",
            "classifier.6.bias - parameter:\n",
            " tensor([ 0.0137, -0.0015,  0.0052, -0.0107,  0.0028,  0.0037, -0.0010,  0.0114,\n",
            "         0.0145, -0.0109,  0.0104,  0.0059,  0.0145, -0.0023, -0.0010,  0.0011,\n",
            "        -0.0048, -0.0044, -0.0056, -0.0028,  0.0041,  0.0097,  0.0028, -0.0173],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' is your trained model\n",
        "torch.save(model.state_dict(), 'model_weights.pth')  # Saves only the weights"
      ],
      "metadata": {
        "id": "yhbfDecexUhr"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}