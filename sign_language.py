# -*- coding: utf-8 -*-
"""Sign_Language.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w_O0lQeLMyQSRSCjGmtIYoV4c1jPlSuW
"""

import torch
import torchvision
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

df_train = pd.read_csv("/content/sign_mnist_train.csv")
df_test = pd.read_csv("/content/sign_mnist_test.csv")

# Separate labels and pixel values
labels_train = df_train.iloc[:, 0].values
pixels_train = df_train.iloc[:, 1:].values
print(f"labels = {labels_train}\npixels = {pixels_train}")

# Separate labels and pixel values
labels_test = df_test.iloc[:, 0].values
pixels_test = df_test.iloc[:, 1:].values
print(f"labels = {labels_test}\npixels = {pixels_test}")

class AlexNet(nn.Module):
  def __init__(self, num_classes, dropout=0.5):
      super(AlexNet, self).__init__()
      self.features = nn.Sequential(
          nn.Conv2d(1, 64, 5, stride=1, padding=2),  # Adjusted kernel size, stride, and padding
          nn.ReLU(inplace=True),
          nn.MaxPool2d(kernel_size=2, stride=2),  # Adjusted kernel size and stride
          nn.Conv2d(64, 192, 5, stride=1, padding=2),
          nn.ReLU(inplace=True),
          nn.MaxPool2d(kernel_size=2, stride=2),
          nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),
          nn.ReLU(inplace=True),
          nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),
          nn.ReLU(inplace=True),
          nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
          nn.ReLU(inplace=True),
          nn.MaxPool2d(kernel_size=2, stride=2)  # Adjusted kernel size and stride
      )
      self.classifier = nn.Sequential(
          nn.Dropout(p=dropout),
          nn.Linear(256 * 3 * 3, 4096),  # Adjusted dimensions based on feature map size
          nn.ReLU(inplace=True),
          nn.Dropout(p=dropout),
          nn.Linear(4096, 4096),
          nn.ReLU(inplace=True),
          nn.Linear(4096, num_classes),  # Adjusted to match the number of classes
          nn.Softmax(dim=1)
      )

  def forward(self, x):
      x = self.features(x)
      x = torch.flatten(x, start_dim=1)  # Flatten the tensor
      x = self.classifier(x)
      return x

NUM_CLASSES = df_train.iloc[:, 0].nunique()
print(f'Number of unique labels: {NUM_CLASSES}')

# Define your device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AlexNet(num_classes=NUM_CLASSES).to(device)
epochs = 500 # number of single passes on the network
loss_fnPrecents = nn.CrossEntropyLoss(ignore_index=24)
optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)

class CustomDataset(Dataset):
    def __init__(self, pixels, labels, transform=None):
        self.pixels = pixels
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = self.pixels[idx].reshape(28, 28).astype('float32')
        label = self.labels[idx].astype('int64')  # Ensure labels are of type int64

        if self.transform:
            image = self.transform(image)

        return image, label

transform = transforms.Compose([
    transforms.ToTensor(),
])
train_dataset = CustomDataset(pixels_train, labels_train, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=100)

# Training loop
def train_model(model, dataloader, epochs, optimizer, loss_fn, device):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = loss_fn(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}")

def evaluate_model(model, dataloader, device):
    model.eval()  # Set the model to evaluation mode
    total, correct = 0, 0
    with torch.no_grad():
        for data, targets in dataloader:
            data, targets = data.to(device), targets.to(device)  # Ensure data and targets are on the correct device
            outputs = model(data)
            _, predicted = torch.max(outputs.data, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

    accuracy = 100 * correct / total  # Calculate accuracy as a percentage
    print(f"Total Correct: {correct}")
    print(f"Total Samples: {total}")
    print(f"Accuracy: {accuracy}%")

train_model(model=model,
            dataloader=train_dataloader,
            epochs=epochs,
            optimizer=optimizer,
            loss_fn=loss_fnPrecents,
            device=device)

val_dataset = CustomDataset(pixels_test, labels_test, transform=transform)
val_dataloader = DataLoader(val_dataset, batch_size=100)

evaluate_model(
    model=model,
    dataloader=train_dataloader,
    device=device
)

evaluate_model(
    model=model,
    dataloader=val_dataloader,
    device=device
)

for name, param in model.named_parameters():
    print(f"{name} - parameter:\n", param.data)

# Assuming 'model' is your trained model
torch.save(model.state_dict(), 'model_weights.pth')  # Saves only the weights